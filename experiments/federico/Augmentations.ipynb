{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will use the nlpaug package, see dependencies here: https://github.com/makcedward/nlpaug, which\n",
    "# probably will need to be installed if you want to run this (and when we add this to the module)\n",
    "# It should (theoretically) be more widely used than the textattack package, and it looks more flexible and diverse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What attacks to add?\n",
    "On the theoretical side of things, we want to add augmentations (attacks), that we think will be likely to throw off the model.\n",
    "There is no point in adding keyboard-driven mis-spellings or randomly shuffling words in a phrase since that will probably be too artificial and distant from the actual use-case of the model.\n",
    "\n",
    "Attacks that would make sense to me, going into increasing order of how much it could break the model, are the following:\n",
    "1. Changing random words with synonyms.\n",
    "2. Changing random words with others with a similar embedding.\n",
    "3. Changing random words with a plausible spelling mistake\n",
    "4. Adding filler words.\n",
    "5. Changing random words with antonyms (this should not change the argumentative structure, only the contents of the argument).\n",
    "6. Changing only the first word of a phrase (a likely B token) with its antonym.\n",
    "7. Paraphrase (or summarise) using other models (already in the nlpaug library).\n",
    "8. Injecting a filler argumentative expression (from TUDarmstadt guide pdf) at the beginning of a phrase\n",
    "\n",
    "Also note that we could divide these in two major categories, namely word insertions and word substitutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/fededagos/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/fededagos/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/fededagos/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas\n",
    "\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\"From this point of view, I firmly believe that we should attach more importance to cooperation during primary education.\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: for every augmenter we can choose the minimum and maximum number of words to change/insert, and with which probability to do so. Defaults are: min = 1, max = 10, p = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synonym\n",
    "Requires downloading dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "['From this point of view, I firmly believe that we should attach more importance to cooperation during primary education.']\n",
      "Augmented Text:\n",
      "['From this point of vista, I firm think that we should attach more than importance to cooperation during chief education.']\n"
     ]
    }
   ],
   "source": [
    "aug = naw.SynonymAug()\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random word insertion /substitution\n",
    "Needs to download BERT (or any other model in transformers).\n",
    "Results of this look pretty cool, and the attack also makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "['From this point of view, I firmly believe that we should attach more importance to cooperation during primary education.']\n",
      "Augmented Text:\n",
      "['from this point be of view, and i firmly believe strongly that we children should attach dramatically more importance to cooperation than during proper primary education.']\n"
     ]
    }
   ],
   "source": [
    "aug = naw.ContextualWordEmbsAug(\n",
    "    model_path='bert-base-uncased', action=\"insert\")\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random spelling mistakes\n",
    "It is supposed to use random spelling mistakes from dictionaries, but looks quite bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "['From this point of view, I firmly believe that we should attach more importance to cooperation during primary education.']\n",
      "Augmented Texts:\n",
      "['Fron ths point of view, I firmely believe thai me should attack more importance to cooperation during primay education.']\n"
     ]
    }
   ],
   "source": [
    "aug = naw.SpellingAug()\n",
    "augmented_texts = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Texts:\")\n",
    "print(augmented_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Antonyms\n",
    "Also depends on downloaded dictionaries. This looks like one of the most interesting: changing the sentiment and or the contents of a claim still make it a claim: will the model pick up on this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "['From this point of view, I firmly believe that we should attach more importance to cooperation during primary education.']\n",
      "Augmented Text:\n",
      "['From this point of view, I firmly disbelieve that we should detach less importance to cooperation during secondary education.']\n"
     ]
    }
   ],
   "source": [
    "aug = naw.AntonymAug()\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarisation\n",
    "This requires downloading T5. Results can look like BS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "['From this point of view, I firmly believe that we should attach more importance to cooperation during primary education.']\n",
      "Augmented Text:\n",
      "['timothy stanley: we should attach more importance to cooperation during primary education. he says i firmly believe that we should give more emphasis to cooperation.']\n"
     ]
    }
   ],
   "source": [
    "aug = nas.AbstSummAug(model_path='t5-base')\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random keyword change\n",
    "The following is interesting: we can define a list of \"reserved words\" and the augmenter will swap each reserved word with another one from the list at random. We could change groups of logical connectives in this way, or overload the use of prepositions after the subject, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "['From this point of view, I firmly believe that we should attach more importance to cooperation during primary education.']\n",
      "Augmented Text:\n",
      "['From this point of view, I therefore firmly believe that we should attach more importance to cooperation during primary education.']\n"
     ]
    }
   ],
   "source": [
    "reserved_tokens = [\n",
    "    [\"I\", \"I therefore\"],\n",
    "]\n",
    "reserved_aug = naw.ReservedAug(reserved_tokens=reserved_tokens)\n",
    "augmented_text = reserved_aug.augment(text)\n",
    "\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more extensive example is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "['From this point of view, I firmly believe that we should attach more importance to cooperation during primary education.']\n",
      "Augmented Text:\n",
      "['From this point of view, I basically firmly believe that we should attach more importance to cooperation during primary education.']\n"
     ]
    }
   ],
   "source": [
    "reserved_tokens = [\n",
    "    [\n",
    "        \"I\",\n",
    "        \"I therefore\",\n",
    "        \"I actually\",\n",
    "        \"I basically\",\n",
    "        \"I seriously\",\n",
    "        \"I really\",\n",
    "        \"I highly\",\n",
    "        \"I totally\",\n",
    "        \"I absolutely\",\n",
    "    ],\n",
    "]\n",
    "reserved_aug = naw.ReservedAug(reserved_tokens=reserved_tokens)\n",
    "augmented_text = reserved_aug.augment(text)\n",
    "\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom fillers from TuDarmstadt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filler_augment(text, fillers=None):\n",
    "    \"\"\"Augments the beginning of text with a phrase taken from a list of pre-defined filler phrases.\n",
    "    The filler phrases are taken from the TUDarmstadt annotation guidelines, with the addition of some\n",
    "    other common fillers used in english.\"\"\"\n",
    "    if fillers is None:\n",
    "        fillers = [\n",
    "            \"According to the previous fact, \",\n",
    "            \"As can be seen, \",\n",
    "            \"For example, \",\n",
    "            \"Another important point which contributes to my argument is that \",\n",
    "            \"I agree to this view that \",\n",
    "            \"In this context, \",\n",
    "            \"At the end of the day, \",\n",
    "        ]\n",
    "    random_idx = np.random.choice(len(fillers))\n",
    "    filler = fillers[random_idx]\n",
    "    aug_text = filler + text[0].lower() + text[1:]\n",
    "    \n",
    "    return aug_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I agree to this view that from this point of view, I firmly believe that we should attach more importance to cooperation during primary education.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filler_augment(text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ee6a9a8b61699f32b5a7a55c4b76a23d31b5e19b5306abe9fe34779c1ab572f7"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 ('python10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
