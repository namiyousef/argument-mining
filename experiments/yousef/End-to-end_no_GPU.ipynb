{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c2ec16d",
   "metadata": {},
   "source": [
    "# End-to-end\n",
    "\n",
    "This notebook should form the core skeleton of the 'run' function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1302e4f",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d8ed729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# -- public imports\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from pandas.testing import assert_frame_equal\n",
    "import time\n",
    "\n",
    "# -- private imports\n",
    "from colabtools.utils import move_to_device\n",
    "\n",
    "# -- dev imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from argminer.data import ArgumentMiningDataset, TUDarmstadtProcessor\n",
    "from argminer.evaluation import inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "59272e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants (these will be abstracted away by inputs that you give to run)\n",
    "model_name = 'google/bigbird-roberta-base'\n",
    "max_length = 1024\n",
    "epochs = 1\n",
    "batch_size = 2\n",
    "strategy = 'standard_bio'\n",
    "strat_name = strategy.split('_')[1]\n",
    "DEVICE = 'cpu'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b81b26",
   "metadata": {},
   "source": [
    "### Tokenizer, Model and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "882197f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n",
      "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BigBirdForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BigBirdForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BigBirdForTokenClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=15) \n",
    "# TODO force_download\n",
    "# TODO add option for optimizer\n",
    "optimizer = torch.optim.Adam(params=model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3e225a",
   "metadata": {},
   "source": [
    "### Dataset \n",
    "Note this will change as the Processor develops. On the cluster you will need to use different options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ccc67877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found non-matching segments:--------------------------------------------------\n",
      "\n",
      "murdering criminals is therefore immoral and hard to accept\n",
      "\n",
      "\"murdering\" criminals is therefore immoral and hard to accept\n",
      "\n",
      "Found non-matching segments:--------------------------------------------------\n",
      "\n",
      "Click is a very interesting comedy, with a serious approach about the importance of having a balanced life between family and work businesses\n",
      "\n",
      "\"Click\" is a very interesting comedy, with a serious approach about the importance of having a balanced life between family and work businesses\n",
      "\n",
      "Found non-matching segments:--------------------------------------------------\n",
      "\n",
      "Blood diamond, an adaptation of a real story in South Africa, focuses on the link between diamonds and conflict\n",
      "\n",
      "\"Blood diamond\", an adaptation of a real story in South Africa, focuses on the link between diamonds and conflict\n",
      "\n",
      "Found non-matching segments:--------------------------------------------------\n",
      "\n",
      "rush hours are usually not the direct consequence of drivers\n",
      "\n",
      "\"rush hours\" are usually not the direct consequence of drivers\n",
      "\n"
     ]
    }
   ],
   "source": [
    "processor = TUDarmstadtProcessor('../../data/UCL/dataset2/ArgumentAnnotatedEssays-2.0/brat-project-final')\n",
    "processor = processor.preprocess().process(strat_name).postprocess()\n",
    "df_total = processor.dataframe\n",
    "df_train = df_total[['text', 'labels']].head(201) \n",
    "df_test = df_total[['text', 'labels']].tail(201)\n",
    "\n",
    "assert_frame_equal(df_total[['text', 'labels']], pd.concat([df_train, df_test]))\n",
    "\n",
    "# todo this changes NOTE FIXED BT STRATEGY!!\n",
    "df_label_map = pd.DataFrame({\n",
    "    'label_id':[0,1,2,3,4,5,6],\n",
    "    'label':['O', 'B-MajorClaim', 'I-MajorClaim', 'B-Claim', 'I-Claim', 'B-Premise', 'I-Premise']\n",
    "})\n",
    "\n",
    "assert set(df_train.labels.values[0]) == set(df_label_map.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ccf36a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = ArgumentMiningDataset(df_label_map, df_train, tokenizer, max_length, strategy)\n",
    "test_set = ArgumentMiningDataset(df_label_map, df_test, tokenizer, max_length, strategy, is_train=False)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2aa673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(DEVICE)\n",
    "print(f'Model pushed to device: {DEVICE}')\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    start_epoch_message = f'EPOCH {epoch + 1} STARTED'\n",
    "    print(start_epoch_message)\n",
    "    print(f'{\"-\" * len(start_epoch_message)}')\n",
    "    start_epoch = time.time()\n",
    "\n",
    "    start_load = time.time()\n",
    "    training_loss = 0\n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        start_train = time.time()\n",
    "        inputs = move_to_device(inputs, DEVICE)\n",
    "        targets = move_to_device(targets, DEVICE)\n",
    "        if DEVICE != 'cpu':\n",
    "            print(f'GPU Utilisation at batch {i+1} after data loading: {get_gpu_utilization()}')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss, outputs = model(\n",
    "            labels=targets,\n",
    "            input_ids=inputs['input_ids'],\n",
    "            attention_mask=inputs['attention_mask'],\n",
    "            return_dict=False\n",
    "        )\n",
    "        if DEVICE != 'cpu':\n",
    "            print(f'GPU Utilisation at batch {i+1} after training: {get_gpu_utilization()}')\n",
    "\n",
    "\n",
    "        training_loss += loss.item()\n",
    "\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        del targets, inputs, loss, outputs\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        end_train = time.time()\n",
    "\n",
    "        if verbose > 1:\n",
    "            print(\n",
    "                f'Batch {i + 1} complete. Time taken: load({start_train - start_load:.3g}), '\n",
    "                f'train({end_train - start_train:.3g}), total({end_train - start_load:.3g}). '\n",
    "            )\n",
    "        start_load = time.time()\n",
    "\n",
    "    print_message = f'Epoch {epoch + 1}/{epochs} complete. ' \\\n",
    "                    f'Time taken: {start_load - start_epoch:.3g}. ' \\\n",
    "                    f'Loss: {training_loss/(i+1): .3g}'\n",
    "\n",
    "    if verbose:\n",
    "        print(f'{\"-\" * len(print_message)}')\n",
    "        print(print_message)\n",
    "        print(f'{\"-\" * len(print_message)}')\n",
    "\n",
    "    if epoch % save_freq == 0:\n",
    "        encoded_model_name = encode_model_name(model_name, epoch+1)\n",
    "        save_path = f'models/{encoded_model_name}.pt'\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f'Model saved at epoch {epoch+1} at: {save_path}')\n",
    "\n",
    "encoded_model_name = encode_model_name(model_name, 'final')\n",
    "save_path = f'models/{encoded_model_name}.pt'\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f'Model saved at epoch {epoch + 1} at: {save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12afdc17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd86b6d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "argument-mining",
   "language": "python",
   "name": "argument-mining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
