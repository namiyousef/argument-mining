{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c88b4628",
      "metadata": {
        "id": "c88b4628",
        "outputId": "92ef9a20-c9e1-426b-9d23-c9a4f39c9ae9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting argminer@ git+https://github.com/namiyousef/argument-mining.git@develop\n",
            "  Cloning https://github.com/namiyousef/argument-mining.git (to revision develop) to /tmp/pip-install-pvauaoei/argminer_be5a9b3d68214639b7cdef015ef9ce26\n",
            "  Running command git clone -q https://github.com/namiyousef/argument-mining.git /tmp/pip-install-pvauaoei/argminer_be5a9b3d68214639b7cdef015ef9ce26\n",
            "Collecting mlutils@ git+https://git@github.com/namiyousef/ml-utils.git@develop\n",
            "  Cloning https://****@github.com/namiyousef/ml-utils.git (to revision develop) to /tmp/pip-install-pvauaoei/mlutils_03245099f2ad467f85afcc1ec64b8c0f\n",
            "  Running command git clone -q 'https://****@github.com/namiyousef/ml-utils.git' /tmp/pip-install-pvauaoei/mlutils_03245099f2ad467f85afcc1ec64b8c0f\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from argminer@ git+https://github.com/namiyousef/argument-mining.git@develop) (1.10.0+cu111)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 5.1 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 40.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from argminer@ git+https://github.com/namiyousef/argument-mining.git@develop) (1.3.5)\n",
            "Requirement already satisfied: plac in /usr/local/lib/python3.7/dist-packages (from argminer@ git+https://github.com/namiyousef/argument-mining.git@develop) (1.1.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from argminer@ git+https://github.com/namiyousef/argument-mining.git@develop) (1.21.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from argminer@ git+https://github.com/namiyousef/argument-mining.git@develop) (4.64.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from argminer@ git+https://github.com/namiyousef/argument-mining.git@develop) (0.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from argminer@ git+https://github.com/namiyousef/argument-mining.git@develop) (3.17.3)\n",
            "Collecting colab-dev-tools\n",
            "  Downloading colab_dev_tools-0.0.7-py3-none-any.whl (3.7 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from argminer@ git+https://github.com/namiyousef/argument-mining.git@develop) (3.2.2)\n",
            "Collecting connexion[swagger-ui]\n",
            "  Downloading connexion-2.13.0-py2.py3-none-any.whl (95 kB)\n",
            "\u001b[K     |████████████████████████████████| 95 kB 3.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.7/dist-packages (from colab-dev-tools->argminer@ git+https://github.com/namiyousef/argument-mining.git@develop) (7.352.0)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from connexion[swagger-ui]->argminer@ git+https://github.com/namiyousef/argument-mining.git@develop) (1.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.9.1 in /usr/local/lib/python3.7/dist-packages (from connexion[swagger-ui]->argminer@ git+https://github.com/namiyousef/argument-mining.git@develop) (2.23.0)\n",
            "Collecting clickclick<21,>=1.2\n",
            "  Downloading clickclick-20.10.2-py2.py3-none-any.whl (7.4 kB)\n",
            "Requirement already satisfied: werkzeug<3,>=1.0 in /usr/local/lib/python3.7/dist-packages (from connexion[swagger-ui]->argminer@ git+https://github.com/namiyousef/argument-mining.git@develop) (1.0.1)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.7/dist-packages (from connexion[swagger-ui]->argminer@ git+https://github.com/namiyousef/argument-mining.git@develop) (21.3)\n",
            "Requirement already satisfied: jsonschema<5,>=2.5.1 in /usr/local/lib/python3.7/dist-packages (from connexion[swagger-ui]->argminer@ git+https://github.com/namiyousef/argument-mining.git@develop) (4.3.3)\n",
            "Collecting inflection<0.6,>=0.3.1\n",
            "  Downloading inflection-0.5.1-py2.py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: importlib-metadata>=1 in /usr/local/lib/python3.7/dist-packages (from connexion[swagger-ui]->argminer@ git+https://github.com/namiyousef/argument-mining.git@develop) (4.11.3)\n",
            "Collecting PyYAML<7,>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 31.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: flask<3,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from connexion[swagger-ui]->argminer@ git+https://github.com/namiyousef/argument-mining.git@develop) (1.1.4)\n",
            "Collecting swagger-ui-bundle<0.1,>=0.0.2\n",
            "  Downloading swagger_ui_bundle-0.0.9-py3-none-any.whl (6.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.2 MB 31.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from clickclick<21,>=1.2->connexion[swagger-ui]->argminer@ git+https://github.com/namiyousef/argument-mining.git@develop) (7.1.2)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask<3,>=1.0.4->connexion[swagger-ui]->argminer@ git+https://github.com/namiyousef/argument-mining.git@develop) (2.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1->connexion[swagger-ui]->argminer@ git+https://github.com/namiyousef/argument-mining.git@develop) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1->connexion[swagger-ui]->argminer@ git+https://github.com/namiyousef/argument-mining.git@develop) (3.8.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask<3,>=1.0.4->connexion[swagger-ui]->argminer@ git+https://github.com/namiyousef/argument-mining.git@develop) (2.0.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema<5,>=2.5.1->connexion[swagger-ui]->argminer@ git+https://github.com/namiyousef/argument-mining.git@develop) (21.4.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema<5,>=2.5.1->connexion[swagger-ui]->argminer@ git+https://github.com/namiyousef/argument-mining.git@develop) (5.6.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema<5,>=2.5.1->connexion[swagger-ui]->argminer@ git+https://github.com/namiyousef/argument-mining.git@develop) (0.18.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20->connexion[swagger-ui]->argminer@ git+https://github.com/namiyousef/argument-mining.git@develop) (3.0.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.9.1->connexion[swagger-ui]->argminer@ git+https://github.com/namiyousef/argument-mining.git@develop) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.9.1->connexion[swagger-ui]->argminer@ git+https://github.com/namiyousef/argument-mining.git@develop) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.9.1->connexion[swagger-ui]->argminer@ git+https://github.com/namiyousef/argument-mining.git@develop) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.9.1->connexion[swagger-ui]->argminer@ git+https://github.com/namiyousef/argument-mining.git@develop) (2021.10.8)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->argminer@ git+https://github.com/namiyousef/argument-mining.git@develop) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->argminer@ git+https://github.com/namiyousef/argument-mining.git@develop) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->argminer@ git+https://github.com/namiyousef/argument-mining.git@develop) (1.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->argminer@ git+https://github.com/namiyousef/argument-mining.git@develop) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->argminer@ git+https://github.com/namiyousef/argument-mining.git@develop) (2018.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->argminer@ git+https://github.com/namiyousef/argument-mining.git@develop) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->argminer@ git+https://github.com/namiyousef/argument-mining.git@develop) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->argminer@ git+https://github.com/namiyousef/argument-mining.git@develop) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->argminer@ git+https://github.com/namiyousef/argument-mining.git@develop) (1.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->argminer@ git+https://github.com/namiyousef/argument-mining.git@develop) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 38.8 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->argminer@ git+https://github.com/namiyousef/argument-mining.git@develop) (3.6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 38.5 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: argminer, mlutils\n",
            "  Building wheel for argminer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for argminer: filename=argminer-0.0.19-py3-none-any.whl size=30170 sha256=48029b1804fafafaa4a012e56d0c87c9d4abe744ee37fa0ce7da57e79d4cc9fc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-e8761gci/wheels/d0/86/ef/e5723b21ea72191b54f26ce72340113c8ee0a21b4e6f05ae49\n",
            "  Building wheel for mlutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mlutils: filename=mlutils-0.0.2-py3-none-any.whl size=4404 sha256=80af7683e35963bb597db3abb4b7fa3a4ffedc4f623ba236b5b0d061dabd9e24\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-e8761gci/wheels/56/12/28/e154e37dd9619b36d94a0e995f2e0a5ab4cadbfb0ac7637436\n",
            "Successfully built argminer mlutils\n",
            "Installing collected packages: PyYAML, inflection, clickclick, tokenizers, swagger-ui-bundle, sacremoses, huggingface-hub, connexion, transformers, sentencepiece, mlutils, colab-dev-tools, argminer\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-6.0 argminer-0.0.19 clickclick-20.10.2 colab-dev-tools-0.0.7 connexion-2.13.0 huggingface-hub-0.5.1 inflection-0.5.1 mlutils-0.0.2 sacremoses-0.0.49 sentencepiece-0.1.96 swagger-ui-bundle-0.0.9 tokenizers-0.12.1 transformers-4.18.0\n",
            "CUDA device detected. Using GPU...\n",
            "Google Drive import successful.\n"
          ]
        }
      ],
      "source": [
        "!pip install argminer@git+https://github.com/namiyousef/argument-mining.git@develop\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "import warnings\n",
        "from argminer.data import ArgumentMiningDataset, PersuadeProcessor, TUDarmstadtProcessor\n",
        "from argminer.utils import decode_model_name\n",
        "from argminer.evaluation import inference\n",
        "from argminer.config import LABELS_MAP_DICT\n",
        "import time\n",
        "from torch.utils.data import DataLoader\n",
        "from mlutils.torchtools.metrics import FScore"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3ce3f0c",
      "metadata": {
        "id": "a3ce3f0c"
      },
      "source": [
        "## PATHS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c74cf0fa",
      "metadata": {
        "id": "c74cf0fa",
        "outputId": "55d13e8d-e117-4251-c466-0662a98f79a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: colab-dev-tools in /usr/local/lib/python3.7/dist-packages (0.0.7)\n",
            "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.7/dist-packages (from colab-dev-tools) (7.352.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from colab-dev-tools) (1.10.0+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from colab-dev-tools) (1.21.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->colab-dev-tools) (4.1.1)\n",
            "Mounted at /content/drive\n",
            "Google Drive mount successful.\n"
          ]
        }
      ],
      "source": [
        "# need to have a relative load of the models\n",
        "!pip install colab-dev-tools\n",
        "from colabtools.utils import mount_drive\n",
        "import os\n",
        "\n",
        "drive_path = mount_drive()\n",
        "BASE_PATH = os.path.join(drive_path, 'Desktop/')\n",
        "\n",
        "# path to models\n",
        "JOB_DIR = os.path.join(BASE_PATH, 'tmpdir/job')\n",
        "TEST_DIR = os.path.join(BASE_PATH, 'test')\n",
        "MODEL_PATH = os.path.join(drive_path, 'COMP0087/data/core')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fec9a578",
      "metadata": {
        "id": "fec9a578"
      },
      "outputs": [],
      "source": [
        "# TODO double check config MAP!\n",
        "CONFIG_MAP = {\n",
        "    '822594.undefined': dict(\n",
        "        processor=PersuadeProcessor,\n",
        "        strat='bieo',\n",
        "        dataset='Persuade',\n",
        "    ),\n",
        "    '822595.undefined': dict(\n",
        "        processor=PersuadeProcessor,\n",
        "        strat='bio',\n",
        "        dataset='Persuade'\n",
        "    ),\n",
        "    '822596.undefined': dict(\n",
        "        processor=PersuadeProcessor,\n",
        "        strat='io',\n",
        "        dataset='Persuade'\n",
        "    ),\n",
        "    '820966.undefined': dict(\n",
        "        processor=PersuadeProcessor,\n",
        "        strat='bieo',\n",
        "        dataset='Persuade'\n",
        "    ),\n",
        "    '820965.undefined': dict(\n",
        "       processor=PersuadeProcessor,\n",
        "        strat='bio',\n",
        "        dataset='Persuade'\n",
        "    ),\n",
        "    '820962.undefined': dict(\n",
        "        processor=PersuadeProcessor,\n",
        "        strat='io',\n",
        "        dataset='Persuade'\n",
        "    ),\n",
        "    '820985.undefined': dict(\n",
        "        processor=TUDarmstadtProcessor,\n",
        "        strat='bieo',\n",
        "        dataset='TUDarmstadt'\n",
        "    ),\n",
        "    '820986.undefined': dict(\n",
        "        processor=TUDarmstadtProcessor,\n",
        "        strat='bio',\n",
        "        dataset='TUDarmstadt'\n",
        "    ),\n",
        "    '820987.undefined': dict(\n",
        "        processor=TUDarmstadtProcessor,\n",
        "        strat='io',\n",
        "        dataset='TUDarmstadt'\n",
        "    ),\n",
        "    '826025.undefined': dict(\n",
        "        processor=TUDarmstadtProcessor,\n",
        "        strat='bieo',\n",
        "        dataset='TUDarmstadt'\n",
        "    ),\n",
        "    '826026.undefined': dict(\n",
        "        processor=TUDarmstadtProcessor,\n",
        "        strat='bio',\n",
        "        dataset='TUDarmstadt'\n",
        "    ),\n",
        "    '826027.undefined': dict(\n",
        "        processor=TUDarmstadtProcessor,\n",
        "        strat='io',\n",
        "        dataset='TUDarmstadt'\n",
        "    ),\n",
        "\n",
        "}\n",
        "\n",
        "MAX_LENGTH_DICT = {\n",
        "    'google/bigbird-roberta-base': 1024,\n",
        "    'roberta-base': 512\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f9512f59",
      "metadata": {
        "id": "f9512f59"
      },
      "outputs": [],
      "source": [
        "RESULTS = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "448f6abf",
      "metadata": {
        "id": "448f6abf"
      },
      "outputs": [],
      "source": [
        "#metrics = [FScore(average='macro')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5b8fec1c",
      "metadata": {
        "id": "5b8fec1c"
      },
      "outputs": [],
      "source": [
        "def _get_loader(df_label_map, df_test, batch_size):\n",
        "    testset = ArgumentMiningDataset(\n",
        "        df_label_map, df_test, tokenizer, max_length, f'standard_{strategy}', is_train=False\n",
        "    )\n",
        "    testloader = DataLoader(testset, batch_size=batch_size)\n",
        "    return testloader\n",
        "\n",
        "def _get_data(path, Processor, strategy, batch_size=32, limit=None):\n",
        "    processor = Processor(path).from_json()\n",
        "    if 'test' in path:\n",
        "        df_test = processor.dataframe[['text', 'labels']]\n",
        "        # TODO here might need to do a label_map\n",
        "    else:\n",
        "        df_dict = processor.get_tts(test_size=0.3)\n",
        "        df_test = df_dict['test'][['text', 'labels']]\n",
        "    if limit is not None:\n",
        "        warnings.warn('LOADING LIMITED DATA')\n",
        "        df_test = df_test.head(limit)\n",
        "    \n",
        "    df_label_map = LABELS_MAP_DICT[processor.__class__.__name__.split('Processor')[0]][strategy]\n",
        "    return df_test, df_label_map\n",
        "\n",
        "def _get_core_data(path, Processor, strategy, batch_size=32, limit=None):\n",
        "    #processor = Processor(path).from_json()\n",
        "    #if 'test' in path:\n",
        "    #    print( processor.dataframe.head())\n",
        "    #    df_test = processor.dataframe[['text', 'labels']]\n",
        "    #else:\n",
        "    #    df_dict = processor.get_tts(test_size=0.3)\n",
        "    #    df_test = df_dict['test'][['text', 'labels']]\n",
        "    #if limit is not None:\n",
        "    #    warnings.warn('LOADING LIMITED DATA')\n",
        "    #   df_test = df_test.head(limit)\n",
        "    \n",
        "    #df_label_map = LABELS_MAP_DICT[processor.__class__.__name__.split('Processor')[0]][strategy]\n",
        "    \n",
        "    #testset = ArgumentMiningDataset(\n",
        "    #    df_label_map, df_test, tokenizer, max_length, f'standard_{strategy}', is_train=False\n",
        "    #)\n",
        "    #testloader = DataLoader(testset, batch_size=batch_size)\n",
        "    df_test, df_label_map = _get_data(path, Processor, strategy, batch_size, limit)\n",
        "    testloader = _get_loader(df_label_map, df_test, batch_size)\n",
        "    \n",
        "    return testloader\n",
        "\n",
        "\n",
        "def _get_other_data(path, Processor, strategy, batch_size=32, limit=None):\n",
        "    if Processor == PersuadeProcessor:\n",
        "        # we are using a Persuade Model but would like to test on TUDarmstadt\n",
        "        df_test, _ = _get_data(path, TUDarmstadtProcessor, strategy, batch_size, limit)\n",
        "        # HARD RESET DF-LABEL-MAP\n",
        "        df_label_map = LABELS_MAP_DICT['Persuade'][strategy]\n",
        "        \n",
        "        label_map_dict = {\n",
        "            'Claim': 'Claim',\n",
        "            'MajorClaim': 'Position',\n",
        "            'Premise': 'O',\n",
        "            'O': 'O'\n",
        "        }\n",
        "        \n",
        "    else:\n",
        "        df_test, _ = _get_data(path, PersuadeProcessor, strategy, batch_size, limit)\n",
        "        df_label_map = LABELS_MAP_DICT['TUDarmstadt'][strategy]\n",
        "\n",
        "\n",
        "        label_map_dict = {\n",
        "            'Lead': 'O',\n",
        "            'Rebuttal': 'O',\n",
        "            'Concluding Statement': 'O',\n",
        "            'Position': 'MajorClaim',\n",
        "            'Evidence': 'O',\n",
        "            'Claim': 'Claim',\n",
        "            'Counterclaim': 'O',\n",
        "            'O': 'O'\n",
        "        }\n",
        "    df_test.labels = df_test.labels.apply(\n",
        "        lambda x: [\n",
        "            'O' if label_map_dict[text.split('-')[-1]] =='O' else text.replace(\n",
        "                text.split('-')[-1],\n",
        "                label_map_dict[text.split('-')[-1]]\n",
        "            ) for text in x]\n",
        "    )\n",
        "\n",
        "\n",
        "    testloader = _get_loader(df_label_map, df_test, batch_size)\n",
        "    return testloader\n",
        "\n",
        "def _get_scores_agg(df):\n",
        "    df = df.groupby('class').sum()\n",
        "    df['f1'] = df.tp / (df.tp + 1/2*(df.fp + df.fn))\n",
        "    df['recall'] = df.tp / (df.tp + df.fn)\n",
        "    df['precision'] = df.tp / (df.tp + df.fp)\n",
        "    avgs = {'f1':df['f1'].mean(), 'recall': df['recall'].mean(), 'precision': df['precision'].mean()}\n",
        "    return avgs, df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "14354111",
      "metadata": {
        "id": "14354111"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "LIMIT = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "b331ab21",
      "metadata": {
        "scrolled": false,
        "id": "b331ab21",
        "outputId": "9a5d4247-e458-40a4-a3b4-2901ad9edc79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/12: TUDarmstadt->roberta-base->bieo at PATH: drive/MyDrive/Desktop/tmpdir/job/826025.undefined/models/cm9iZXJ0YS1iYXNlX2ZpbmFs\n",
            "=================================================================================\n",
            "Loaded and data loaded. Time:  1.61\n",
            "Prediction time: 0.017\n",
            "Agg to word time: 5.31\n",
            "Get predstring time: 0.374\n",
            "Evaluate time: 1.56\n",
            "Batch 1 complete.\n",
            "Took 7.96 to get scores\n",
            "RUNNING AUGMENTATION: custom_fillers\n",
            "Prediction time: 0.0188\n",
            "Agg to word time: 6.24\n",
            "Get predstring time: 0.391\n",
            "Evaluate time: 1.43\n",
            "Batch 1 complete.\n",
            "RUNNING AUGMENTATION: synonym\n",
            "Prediction time: 0.017\n",
            "Agg to word time: 5.47\n",
            "Get predstring time: 0.369\n",
            "Evaluate time: 1.55\n",
            "Batch 1 complete.\n",
            "RUNNING AUGMENTATION: spellingError\n",
            "Prediction time: 0.0159\n",
            "Agg to word time: 5.29\n",
            "Get predstring time: 0.364\n",
            "Evaluate time: 1.5\n",
            "Batch 1 complete.\n",
            "RUNNING AUGMENTATION: keywordChange\n",
            "Prediction time: 0.0187\n",
            "Agg to word time: 5.33\n",
            "Get predstring time: 0.372\n",
            "Evaluate time: 1.54\n",
            "Batch 1 complete.\n",
            "RUNNING AUGMENTATION: antonym\n",
            "Prediction time: 0.0166\n",
            "Agg to word time: 5.37\n",
            "Get predstring time: 0.375\n",
            "Evaluate time: 1.58\n",
            "Batch 1 complete.\n",
            "2/12: TUDarmstadt->roberta-base->bio at PATH: drive/MyDrive/Desktop/tmpdir/job/826026.undefined/models/cm9iZXJ0YS1iYXNlX2ZpbmFs\n",
            "=================================================================================\n",
            "Loaded and data loaded. Time:  2.94\n",
            "Prediction time: 0.0142\n",
            "Agg to word time: 5.33\n",
            "Get predstring time: 0.369\n",
            "Evaluate time: 1.54\n",
            "Batch 1 complete.\n",
            "Took 7.94 to get scores\n",
            "RUNNING AUGMENTATION: antonym\n",
            "Prediction time: 0.016\n",
            "Agg to word time: 5.37\n",
            "Get predstring time: 0.359\n",
            "Evaluate time: 1.54\n",
            "Batch 1 complete.\n",
            "RUNNING AUGMENTATION: synonym\n",
            "Prediction time: 0.0162\n",
            "Agg to word time: 5.5\n",
            "Get predstring time: 0.689\n",
            "Evaluate time: 1.9\n",
            "Batch 1 complete.\n",
            "RUNNING AUGMENTATION: keywordChange\n",
            "Prediction time: 0.0161\n",
            "Agg to word time: 5.32\n",
            "Get predstring time: 0.367\n",
            "Evaluate time: 1.53\n",
            "Batch 1 complete.\n",
            "RUNNING AUGMENTATION: custom_fillers\n",
            "Prediction time: 0.0186\n",
            "Agg to word time: 6.24\n",
            "Get predstring time: 0.347\n",
            "Evaluate time: 1.27\n",
            "Batch 1 complete.\n",
            "RUNNING AUGMENTATION: spellingError\n",
            "Prediction time: 0.0168\n",
            "Agg to word time: 5.31\n",
            "Get predstring time: 0.367\n",
            "Evaluate time: 1.48\n",
            "Batch 1 complete.\n",
            "3/12: TUDarmstadt->roberta-base->io at PATH: drive/MyDrive/Desktop/tmpdir/job/826027.undefined/models/cm9iZXJ0YS1iYXNlX2ZpbmFs\n",
            "=================================================================================\n",
            "Loaded and data loaded. Time:  3.07\n",
            "Prediction time: 0.0144\n",
            "Agg to word time: 5.35\n",
            "Get predstring time: 0.368\n",
            "Evaluate time: 1.56\n",
            "Batch 1 complete.\n",
            "Took 7.98 to get scores\n",
            "RUNNING AUGMENTATION: spellingError\n",
            "Prediction time: 0.0204\n",
            "Agg to word time: 8.12\n",
            "Get predstring time: 0.674\n",
            "Evaluate time: 2\n",
            "Batch 1 complete.\n",
            "RUNNING AUGMENTATION: synonym\n",
            "Prediction time: 0.0166\n",
            "Agg to word time: 6.23\n",
            "Get predstring time: 0.54\n",
            "Evaluate time: 2.62\n",
            "Batch 1 complete.\n",
            "RUNNING AUGMENTATION: keywordChange\n",
            "Prediction time: 0.016\n",
            "Agg to word time: 6.5\n",
            "Get predstring time: 0.493\n",
            "Evaluate time: 1.62\n",
            "Batch 1 complete.\n",
            "RUNNING AUGMENTATION: antonym\n",
            "Prediction time: 0.0161\n",
            "Agg to word time: 7.34\n",
            "Get predstring time: 0.396\n",
            "Evaluate time: 2.57\n",
            "Batch 1 complete.\n",
            "RUNNING AUGMENTATION: custom_fillers\n",
            "Prediction time: 0.0282\n",
            "Agg to word time: 7.71\n",
            "Get predstring time: 0.556\n",
            "Evaluate time: 1.27\n",
            "Batch 1 complete.\n",
            "5/12: TUDarmstadt->google/bigbird-roberta-base->bio at PATH: drive/MyDrive/Desktop/tmpdir/job/820986.undefined/models/Z29vZ2xlL2JpZ2JpcmQtcm9iZXJ0YS1iYXNlX2ZpbmFs\n",
            "=================================================================================\n",
            "Loaded and data loaded. Time:  3.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/big_bird/modeling_big_bird.py:978: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  * num_indices_to_pick_from\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction time: 6.8\n",
            "Agg to word time: 4.41\n",
            "Get predstring time: 0.551\n",
            "Evaluate time: 2.73\n",
            "Batch 1 complete.\n",
            "Took 15.4 to get scores\n",
            "RUNNING AUGMENTATION: antonym\n",
            "Prediction time: 6.82\n",
            "Agg to word time: 4.91\n",
            "Get predstring time: 0.544\n",
            "Evaluate time: 2.45\n",
            "Batch 1 complete.\n",
            "RUNNING AUGMENTATION: synonym\n",
            "Prediction time: 6.85\n",
            "Agg to word time: 4.13\n",
            "Get predstring time: 0.54\n",
            "Evaluate time: 2.55\n",
            "Batch 1 complete.\n",
            "RUNNING AUGMENTATION: keywordChange\n",
            "Prediction time: 6.84\n",
            "Agg to word time: 4.54\n",
            "Get predstring time: 0.352\n",
            "Evaluate time: 2.99\n",
            "Batch 1 complete.\n",
            "RUNNING AUGMENTATION: custom_fillers\n",
            "Prediction time: 6.85\n",
            "Agg to word time: 4.97\n",
            "Get predstring time: 0.375\n",
            "Evaluate time: 1.64\n",
            "Batch 1 complete.\n",
            "RUNNING AUGMENTATION: spellingError\n",
            "Prediction time: 6.85\n",
            "Agg to word time: 3.57\n",
            "Get predstring time: 0.367\n",
            "Evaluate time: 1.56\n",
            "Batch 1 complete.\n",
            "8/12: TUDarmstadt->google/bigbird-roberta-base->io at PATH: drive/MyDrive/Desktop/tmpdir/job/820987.undefined/models/Z29vZ2xlL2JpZ2JpcmQtcm9iZXJ0YS1iYXNlX2ZpbmFs\n",
            "=================================================================================\n",
            "Loaded and data loaded. Time:  3.02\n",
            "Prediction time: 6.83\n",
            "Agg to word time: 3.54\n",
            "Get predstring time: 0.366\n",
            "Evaluate time: 1.55\n",
            "Batch 1 complete.\n",
            "Took 13 to get scores\n",
            "RUNNING AUGMENTATION: spellingError\n",
            "Prediction time: 6.85\n",
            "Agg to word time: 3.65\n",
            "Get predstring time: 0.379\n",
            "Evaluate time: 1.62\n",
            "Batch 1 complete.\n",
            "RUNNING AUGMENTATION: synonym\n",
            "Prediction time: 6.86\n",
            "Agg to word time: 3.97\n",
            "Get predstring time: 0.357\n",
            "Evaluate time: 1.55\n",
            "Batch 1 complete.\n",
            "RUNNING AUGMENTATION: keywordChange\n",
            "Prediction time: 6.85\n",
            "Agg to word time: 3.59\n",
            "Get predstring time: 0.379\n",
            "Evaluate time: 1.6\n",
            "Batch 1 complete.\n",
            "RUNNING AUGMENTATION: antonym\n",
            "Prediction time: 6.87\n",
            "Agg to word time: 3.64\n",
            "Get predstring time: 0.366\n",
            "Evaluate time: 1.56\n",
            "Batch 1 complete.\n",
            "RUNNING AUGMENTATION: custom_fillers\n",
            "Prediction time: 6.87\n",
            "Agg to word time: 4.95\n",
            "Get predstring time: 0.386\n",
            "Evaluate time: 1.72\n",
            "Batch 1 complete.\n",
            "11/12: TUDarmstadt->google/bigbird-roberta-base->bieo at PATH: drive/MyDrive/Desktop/tmpdir/job/820985.undefined/models/Z29vZ2xlL2JpZ2JpcmQtcm9iZXJ0YS1iYXNlX2ZpbmFs\n",
            "=================================================================================\n",
            "Loaded and data loaded. Time:  3\n",
            "Prediction time: 6.85\n",
            "Agg to word time: 3.56\n",
            "Get predstring time: 0.365\n",
            "Evaluate time: 1.59\n",
            "Batch 1 complete.\n",
            "Took 13.1 to get scores\n",
            "RUNNING AUGMENTATION: custom_fillers\n",
            "Prediction time: 6.88\n",
            "Agg to word time: 4.99\n",
            "Get predstring time: 0.373\n",
            "Evaluate time: 1.69\n",
            "Batch 1 complete.\n",
            "RUNNING AUGMENTATION: synonym\n",
            "Prediction time: 6.86\n",
            "Agg to word time: 3.75\n",
            "Get predstring time: 0.367\n",
            "Evaluate time: 1.54\n",
            "Batch 1 complete.\n",
            "RUNNING AUGMENTATION: spellingError\n",
            "Prediction time: 6.87\n",
            "Agg to word time: 3.78\n",
            "Get predstring time: 0.383\n",
            "Evaluate time: 1.57\n",
            "Batch 1 complete.\n",
            "RUNNING AUGMENTATION: keywordChange\n",
            "Prediction time: 6.88\n",
            "Agg to word time: 3.67\n",
            "Get predstring time: 0.364\n",
            "Evaluate time: 1.58\n",
            "Batch 1 complete.\n",
            "RUNNING AUGMENTATION: antonym\n",
            "Prediction time: 6.89\n",
            "Agg to word time: 3.63\n",
            "Get predstring time: 0.364\n",
            "Evaluate time: 1.56\n",
            "Batch 1 complete.\n"
          ]
        }
      ],
      "source": [
        "for MODEL_ID, job in enumerate(os.listdir(JOB_DIR)):\n",
        "    if job != '.DS_Store':\n",
        "        job_path = os.path.join(JOB_DIR, job)\n",
        "        model_dir = os.path.join(job_path, 'models')\n",
        "        model_name = [item for item in os.listdir(model_dir) if item != '.DS_Store'][0]\n",
        "        model_name_decoded = decode_model_name(model_name).split('_')[0] # get base model name\n",
        "        \n",
        "        max_length = MAX_LENGTH_DICT[model_name_decoded]\n",
        "        # define tokenizer\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name_decoded, add_prefix_space=True)\n",
        "        model_path = os.path.join(model_dir, model_name)\n",
        "        \n",
        "        strategy = CONFIG_MAP[job].get('strat')\n",
        "        Processor = CONFIG_MAP[job].get('processor')\n",
        "        dataset = CONFIG_MAP[job].get('dataset')\n",
        "        if dataset == 'Persuade':\n",
        "          continue\n",
        "        print(\n",
        "            f'{MODEL_ID+1}/12: {dataset}->{model_name_decoded}->{strategy} at PATH: {model_path}'\n",
        "        )\n",
        "        print('=================================================================================')\n",
        "        \n",
        "        \n",
        "\n",
        "\n",
        "        s = time.time()\n",
        "        trained_model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
        "        \n",
        "        RESULTS[job] = {}\n",
        "        \n",
        "        # test the model against itself\n",
        "        RESULTS[job]['self'] = {}\n",
        "        \n",
        "        # specify the path to the json\n",
        "        path = os.path.join(MODEL_PATH, strategy)\n",
        "        testloader = _get_core_data(path, Processor, strategy, batch_size=BATCH_SIZE, limit=LIMIT)\n",
        "        print(f'Loaded and data loaded. Time: {time.time() - s: .3g}')\n",
        "\n",
        "\n",
        "        # TODO add metrics support\n",
        "        SELF = 'self'\n",
        "        s = time.time()\n",
        "        df_metrics, df_scores = inference(trained_model, testloader, )\n",
        "        macro_f1, df_scores_agg = _get_scores_agg(df_scores)\n",
        "        RESULTS[job][SELF]['core'] = {'avgs': macro_f1, 'scores': df_scores_agg}\n",
        "        \n",
        "        print(f'Took {time.time() -s:.3g} to get scores')\n",
        "        \n",
        "        \n",
        "        \n",
        "        # test models against self adversarial examples\n",
        "        augmented_path = os.path.join(TEST_DIR, strategy)\n",
        "        for augmentation in os.listdir(augmented_path):\n",
        "            if augmentation != '.DS_Store':\n",
        "                print(f'RUNNING AUGMENTATION: {augmentation}')\n",
        "                augmentation_path = os.path.join(augmented_path, augmentation)\n",
        "                testloader = _get_core_data(augmentation_path, Processor, strategy,\n",
        "                                                       batch_size=BATCH_SIZE, limit=LIMIT)\n",
        "                df_metrics, df_scores = inference(trained_model, testloader, )\n",
        "                macro_f1, df_scores_agg = _get_scores_agg(df_scores)\n",
        "                RESULTS[job][SELF][augmentation] = {'avgs': macro_f1, 'scores': df_scores_agg}\n",
        "                # aggregate the scores\n",
        "        \n",
        "        \n",
        "        '''OTHER = 'other'\n",
        "        RESULTS[job][OTHER] = {}\n",
        "        \n",
        "        # get other processor\n",
        "        testloader = _get_other_data(path, Processor, strategy, batch_size=BATCH_SIZE, limit=LIMIT)\n",
        "        df_metrics, df_scores = inference(trained_model, testloader)\n",
        "        macro_f1, df_scores_agg = _get_scores_agg(df_scores)\n",
        "        RESULTS[job][OTHER]['core'] = {'macro_f1': macro_f1, 'scores': df_scores_agg}\n",
        "        \n",
        "        \n",
        "        for augmentation in os.listdir(augmented_path):\n",
        "            if augmentation != '.DS_Store':\n",
        "                augmentation_path = os.path.join(augmented_path, augmentation)\n",
        "                testloader = _get_other_data(augmentation_path, Processor, strategy,\n",
        "                                             batch_size=BATCH_SIZE, limit=LIMIT)\n",
        "                df_metrics, df_scores = inference(trained_model, testloader)\n",
        "                macro_f1, df_scores_agg = _get_scores_agg(df_scores)\n",
        "                RESULTS[job][OTHER][augmentation] = {'macro_f1': macro_f1, 'scores': df_scores_agg}'''\n",
        "        \n",
        "        #RESULTS[model_name_decoded]['self']['core'] # the score\n",
        "        \n",
        "        \n",
        "        # test model against other datasets, need to convert datasets\n",
        "        #RESULTS[model_name_decoded]['transfer'] = {}\n",
        "\n",
        "\n",
        "        \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2142cf8a",
      "metadata": {
        "scrolled": false,
        "id": "2142cf8a",
        "outputId": "8e210406-fcc9-4bac-9c56-a6be1e5ac863"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'822594.undefined': {'self': {'core': {'macro_f1': 0.46401515151515155,\n",
              "    'scores':         tp   fn   fp        f1\n",
              "    class                         \n",
              "    0      0.0  2.0  4.0  0.000000\n",
              "    1      1.0  1.0  1.0  0.500000\n",
              "    2      1.0  1.0  1.0  0.500000\n",
              "    3      3.0  4.0  6.0  0.375000\n",
              "    6      5.0  0.0  1.0  0.909091\n",
              "    7      1.0  1.0  1.0  0.500000},\n",
              "   'custom_fillers': {'macro_f1': 0.0,\n",
              "    'scores':         tp  fn  fp   f1\n",
              "    class                  \n",
              "    1      0.0   0   2  0.0\n",
              "    2      0.0   1   2  0.0\n",
              "    3      0.0   0   2  0.0\n",
              "    5      0.0   1   1  0.0\n",
              "    6      0.0   1   2  0.0\n",
              "    7      0.0   0   1  0.0},\n",
              "   'synonym': {'macro_f1': 0.0,\n",
              "    'scores':         tp  fn  fp   f1\n",
              "    class                  \n",
              "    1      0.0   0   1  0.0\n",
              "    2      0.0   1   2  0.0\n",
              "    3      0.0   0   4  0.0\n",
              "    5      0.0   1   0  0.0\n",
              "    6      0.0   1   4  0.0},\n",
              "   'keywordChange': {'macro_f1': 0.0,\n",
              "    'scores':         tp  fn  fp   f1\n",
              "    class                  \n",
              "    1      0.0   0   2  0.0\n",
              "    2      0.0   1   4  0.0\n",
              "    3      0.0   0   5  0.0\n",
              "    5      0.0   1   1  0.0\n",
              "    6      0.0   1   3  0.0},\n",
              "   'spellingError': {'macro_f1': 0.0,\n",
              "    'scores':         tp  fn  fp   f1\n",
              "    class                  \n",
              "    1      0.0   0   2  0.0\n",
              "    2      0.0   1   3  0.0\n",
              "    3      0.0   0   2  0.0\n",
              "    5      0.0   1   0  0.0\n",
              "    6      0.0   1   6  0.0},\n",
              "   'antonym': {'macro_f1': 0.0,\n",
              "    'scores':         tp  fn  fp   f1\n",
              "    class                  \n",
              "    1      0.0   0   3  0.0\n",
              "    2      0.0   1   3  0.0\n",
              "    3      0.0   0   3  0.0\n",
              "    4      0.0   0   1  0.0\n",
              "    5      0.0   1   2  0.0\n",
              "    6      0.0   1   9  0.0}},\n",
              "  'other': {'core': {'macro_f1': 0.09294871794871795,\n",
              "    'scores':         tp  fn   fp        f1\n",
              "    class                        \n",
              "    0      0.0  13  8.0  0.000000\n",
              "    1      0.0   0  2.0  0.000000\n",
              "    2      1.0   3  3.0  0.250000\n",
              "    3      2.0   5  4.0  0.307692\n",
              "    6      0.0   0  4.0  0.000000\n",
              "    7      0.0   0  3.0  0.000000},\n",
              "   'custom_fillers': {'macro_f1': 0.08465608465608465,\n",
              "    'scores':         tp  fn   fp        f1\n",
              "    class                        \n",
              "    0      0.0  13  7.0  0.000000\n",
              "    1      0.0   0  3.0  0.000000\n",
              "    2      1.0   3  2.0  0.285714\n",
              "    3      2.0   5  9.0  0.222222\n",
              "    6      0.0   0  6.0  0.000000\n",
              "    7      0.0   0  2.0  0.000000},\n",
              "   'synonym': {'macro_f1': 0.16666666666666666,\n",
              "    'scores':         tp  fn   fp        f1\n",
              "    class                        \n",
              "    0      0.0  13  6.0  0.000000\n",
              "    1      0.0   0  2.0  0.000000\n",
              "    2      2.0   2  0.0  0.666667\n",
              "    3      2.0   5  3.0  0.333333\n",
              "    6      0.0   0  5.0  0.000000\n",
              "    7      0.0   0  2.0  0.000000},\n",
              "   'keywordChange': {'macro_f1': 0.09294871794871795,\n",
              "    'scores':         tp  fn   fp        f1\n",
              "    class                        \n",
              "    0      0.0  13  9.0  0.000000\n",
              "    1      0.0   0  4.0  0.000000\n",
              "    2      1.0   3  3.0  0.250000\n",
              "    3      2.0   5  4.0  0.307692\n",
              "    6      0.0   0  4.0  0.000000\n",
              "    7      0.0   0  2.0  0.000000},\n",
              "   'spellingError': {'macro_f1': 0.1414141414141414,\n",
              "    'scores':         tp  fn   fp        f1\n",
              "    class                        \n",
              "    0      0.0  13  6.0  0.000000\n",
              "    1      0.0   0  2.0  0.000000\n",
              "    2      2.0   2  0.0  0.666667\n",
              "    3      1.0   6  3.0  0.181818\n",
              "    6      0.0   0  3.0  0.000000\n",
              "    7      0.0   0  2.0  0.000000},\n",
              "   'antonym': {'macro_f1': 0.15584415584415584,\n",
              "    'scores':         tp  fn   fp        f1\n",
              "    class                        \n",
              "    0      0.0  13  9.0  0.000000\n",
              "    1      0.0   0  3.0  0.000000\n",
              "    2      2.0   2  1.0  0.571429\n",
              "    3      2.0   5  2.0  0.363636\n",
              "    6      0.0   0  6.0  0.000000\n",
              "    7      0.0   0  2.0  0.000000}}},\n",
              " '820966.undefined': {'self': {'core': {'macro_f1': 0.32765151515151514,\n",
              "    'scores':         tp   fn    fp        f1\n",
              "    class                          \n",
              "    0      1.0  1.0   3.0  0.333333\n",
              "    1      1.0  1.0   1.0  0.500000\n",
              "    2      1.0  1.0   1.0  0.500000\n",
              "    3      5.0  2.0  10.0  0.454545\n",
              "    4      0.0  0.0   2.0  0.000000\n",
              "    5      0.0  0.0   3.0  0.000000\n",
              "    6      4.0  1.0   7.0  0.500000\n",
              "    7      1.0  1.0   3.0  0.333333},\n",
              "   'custom_fillers': {'macro_f1': 0.05555555555555555,\n",
              "    'scores':         tp   fn  fp        f1\n",
              "    class                        \n",
              "    0      0.0  0.0   1  0.000000\n",
              "    1      0.0  0.0   3  0.000000\n",
              "    2      1.0  0.0   4  0.333333\n",
              "    3      0.0  0.0   5  0.000000\n",
              "    5      0.0  1.0   0  0.000000\n",
              "    6      0.0  1.0   6  0.000000},\n",
              "   'synonym': {'macro_f1': 0.1,\n",
              "    'scores':         tp   fn    fp   f1\n",
              "    class                     \n",
              "    1      0.0  0.0   1.0  0.0\n",
              "    2      1.0  0.0   2.0  0.5\n",
              "    3      0.0  0.0  10.0  0.0\n",
              "    5      0.0  1.0   0.0  0.0\n",
              "    6      0.0  1.0  11.0  0.0},\n",
              "   'keywordChange': {'macro_f1': 0.2,\n",
              "    'scores':         tp   fn   fp   f1\n",
              "    class                    \n",
              "    1      0.0  0.0  2.0  0.0\n",
              "    2      1.0  0.0  0.0  1.0\n",
              "    3      0.0  0.0  8.0  0.0\n",
              "    5      0.0  1.0  0.0  0.0\n",
              "    6      0.0  1.0  9.0  0.0},\n",
              "   'spellingError': {'macro_f1': 0.0,\n",
              "    'scores':         tp  fn  fp   f1\n",
              "    class                  \n",
              "    1      0.0   0   1  0.0\n",
              "    2      0.0   1   1  0.0\n",
              "    3      0.0   0   5  0.0\n",
              "    5      0.0   1   0  0.0\n",
              "    6      0.0   1   7  0.0},\n",
              "   'antonym': {'macro_f1': 0.13333333333333333,\n",
              "    'scores':         tp   fn   fp        f1\n",
              "    class                         \n",
              "    1      0.0  0.0  5.0  0.000000\n",
              "    2      1.0  0.0  1.0  0.666667\n",
              "    3      0.0  0.0  2.0  0.000000\n",
              "    5      0.0  1.0  0.0  0.000000\n",
              "    6      0.0  1.0  9.0  0.000000}},\n",
              "  'other': {'core': {'macro_f1': 0.1391941391941392,\n",
              "    'scores':         tp  fn   fp        f1\n",
              "    class                        \n",
              "    0      0.0  13  7.0  0.000000\n",
              "    1      0.0   0  2.0  0.000000\n",
              "    2      2.0   2  0.0  0.666667\n",
              "    3      2.0   5  4.0  0.307692\n",
              "    4      0.0   0  1.0  0.000000\n",
              "    6      0.0   0  5.0  0.000000\n",
              "    7      0.0   0  2.0  0.000000},\n",
              "   'custom_fillers': {'macro_f1': 0.11538461538461539,\n",
              "    'scores':         tp  fn    fp        f1\n",
              "    class                         \n",
              "    0      0.0  13  12.0  0.000000\n",
              "    1      0.0   0   2.0  0.000000\n",
              "    2      2.0   2   2.0  0.500000\n",
              "    3      2.0   5   4.0  0.307692\n",
              "    5      0.0   0   2.0  0.000000\n",
              "    6      0.0   0   7.0  0.000000\n",
              "    7      0.0   0   2.0  0.000000},\n",
              "   'synonym': {'macro_f1': 0.14718614718614717,\n",
              "    'scores':         tp  fn   fp        f1\n",
              "    class                        \n",
              "    0      0.0  13  5.0  0.000000\n",
              "    1      0.0   0  3.0  0.000000\n",
              "    2      2.0   2  0.0  0.666667\n",
              "    3      2.0   5  2.0  0.363636\n",
              "    4      0.0   0  1.0  0.000000\n",
              "    6      0.0   0  5.0  0.000000\n",
              "    7      0.0   0  2.0  0.000000},\n",
              "   'keywordChange': {'macro_f1': 0.11538461538461539,\n",
              "    'scores':         tp  fn   fp        f1\n",
              "    class                        \n",
              "    0      0.0  13  8.0  0.000000\n",
              "    1      0.0   0  2.0  0.000000\n",
              "    2      2.0   2  2.0  0.500000\n",
              "    3      2.0   5  4.0  0.307692\n",
              "    4      0.0   0  3.0  0.000000\n",
              "    6      0.0   0  5.0  0.000000\n",
              "    7      0.0   0  2.0  0.000000},\n",
              "   'spellingError': {'macro_f1': 0.08585858585858586,\n",
              "    'scores':         tp  fn   fp        f1\n",
              "    class                        \n",
              "    0      0.0  13  7.0  0.000000\n",
              "    1      0.0   0  2.0  0.000000\n",
              "    2      1.0   3  1.0  0.333333\n",
              "    3      1.0   6  3.0  0.181818\n",
              "    6      0.0   0  4.0  0.000000\n",
              "    7      0.0   0  2.0  0.000000},\n",
              "   'antonym': {'macro_f1': 0.12925170068027209,\n",
              "    'scores':         tp  fn   fp        f1\n",
              "    class                        \n",
              "    0      0.0  13  9.0  0.000000\n",
              "    1      0.0   0  2.0  0.000000\n",
              "    2      2.0   2  1.0  0.571429\n",
              "    3      2.0   5  3.0  0.333333\n",
              "    4      0.0   0  2.0  0.000000\n",
              "    6      0.0   0  5.0  0.000000\n",
              "    7      0.0   0  2.0  0.000000}}},\n",
              " '820985.undefined': {'self': {'core': {'macro_f1': 0.8198587127158555,\n",
              "    'scores':        tp   fn   fp        f1\n",
              "    class                        \n",
              "    0      23  2.0  1.0  0.938776\n",
              "    1       3  1.0  0.0  0.857143\n",
              "    2       5  2.0  2.0  0.714286\n",
              "    3      10  2.0  4.0  0.769231},\n",
              "   'custom_fillers': {'macro_f1': 0.5019230769230769,\n",
              "    'scores':          tp  fn  fp        f1\n",
              "    class                        \n",
              "    0      15.0  10  12  0.576923\n",
              "    1       1.0   3   5  0.200000\n",
              "    2       3.0   4   3  0.461538\n",
              "    3      10.0   2   4  0.769231},\n",
              "   'synonym': {'macro_f1': 0.6692857142857143,\n",
              "    'scores':        tp   fn   fp        f1\n",
              "    class                        \n",
              "    0      19  6.0  6.0  0.760000\n",
              "    1       3  1.0  0.0  0.857143\n",
              "    2       4  3.0  5.0  0.500000\n",
              "    3       7  5.0  6.0  0.560000},\n",
              "   'keywordChange': {'macro_f1': 0.8198587127158555,\n",
              "    'scores':        tp   fn   fp        f1\n",
              "    class                        \n",
              "    0      23  2.0  1.0  0.938776\n",
              "    1       3  1.0  0.0  0.857143\n",
              "    2       5  2.0  2.0  0.714286\n",
              "    3      10  2.0  4.0  0.769231},\n",
              "   'spellingError': {'macro_f1': 0.6861878881987578,\n",
              "    'scores':        tp    fn    fp        f1\n",
              "    class                          \n",
              "    0      12  13.0  13.0  0.480000\n",
              "    1       3   1.0   0.0  0.857143\n",
              "    2       5   2.0   4.0  0.625000\n",
              "    3       9   3.0   2.0  0.782609},\n",
              "   'antonym': {'macro_f1': 0.7298188405797101,\n",
              "    'scores':        tp   fn   fp        f1\n",
              "    class                        \n",
              "    0      18  7.0  7.0  0.720000\n",
              "    1       3  1.0  1.0  0.750000\n",
              "    2       5  2.0  3.0  0.666667\n",
              "    3       9  3.0  2.0  0.782609}},\n",
              "  'other': {'core': {'macro_f1': 0.05263157894736842,\n",
              "    'scores':         tp  fn  fp        f1\n",
              "    class                       \n",
              "    0      2.0   7   8  0.210526\n",
              "    1      0.0   2   4  0.000000\n",
              "    2      0.0   7   0  0.000000\n",
              "    3      0.0   0   4  0.000000},\n",
              "   'custom_fillers': {'macro_f1': 0.125,\n",
              "    'scores':         tp   fn  fp   f1\n",
              "    class                   \n",
              "    0      2.0  0.0   4  0.5\n",
              "    1      0.0  1.0   1  0.0\n",
              "    2      0.0  0.0   1  0.0\n",
              "    3      0.0  0.0   2  0.0},\n",
              "   'synonym': {'macro_f1': 0.09523809523809523,\n",
              "    'scores':         tp   fn  fp        f1\n",
              "    class                        \n",
              "    0      1.0  1.0   4  0.285714\n",
              "    1      0.0  1.0   0  0.000000\n",
              "    3      0.0  0.0   3  0.000000},\n",
              "   'keywordChange': {'macro_f1': 0.0625,\n",
              "    'scores':         tp   fn  fp    f1\n",
              "    class                    \n",
              "    0      1.0  1.0   5  0.25\n",
              "    1      0.0  1.0   0  0.00\n",
              "    2      0.0  0.0   1  0.00\n",
              "    3      0.0  0.0   3  0.00},\n",
              "   'spellingError': {'macro_f1': 0.05,\n",
              "    'scores':         tp   fn  fp   f1\n",
              "    class                   \n",
              "    0      1.0  1.0   7  0.2\n",
              "    1      0.0  1.0   0  0.0\n",
              "    2      0.0  0.0   4  0.0\n",
              "    3      0.0  0.0   2  0.0},\n",
              "   'antonym': {'macro_f1': 0.07142857142857142,\n",
              "    'scores':         tp   fn  fp        f1\n",
              "    class                        \n",
              "    0      1.0  1.0   4  0.285714\n",
              "    1      0.0  1.0   0  0.000000\n",
              "    2      0.0  0.0   3  0.000000\n",
              "    3      0.0  0.0   2  0.000000}}},\n",
              " '822595.undefined': {'self': {'core': {'macro_f1': 0.38316624895572265,\n",
              "    'scores':         tp   fn   fp        f1\n",
              "    class                         \n",
              "    0      1.0  1.0  5.0  0.250000\n",
              "    1      1.0  1.0  1.0  0.500000\n",
              "    2      1.0  1.0  0.0  0.666667\n",
              "    3      4.0  3.0  8.0  0.421053\n",
              "    4      0.0  0.0  4.0  0.000000\n",
              "    6      4.0  1.0  9.0  0.444444\n",
              "    7      1.0  1.0  2.0  0.400000},\n",
              "   'custom_fillers': {'macro_f1': 0.0,\n",
              "    'scores':         tp  fn  fp   f1\n",
              "    class                  \n",
              "    0      0.0   0   3  0.0\n",
              "    1      0.0   0   7  0.0\n",
              "    2      0.0   1   7  0.0\n",
              "    3      0.0   0   4  0.0\n",
              "    5      0.0   1   0  0.0\n",
              "    6      0.0   1   7  0.0},\n",
              "   'synonym': {'macro_f1': 0.0,\n",
              "    'scores':         tp  fn  fp   f1\n",
              "    class                  \n",
              "    1      0.0   0   2  0.0\n",
              "    2      0.0   1   2  0.0\n",
              "    3      0.0   0   1  0.0\n",
              "    5      0.0   1   1  0.0\n",
              "    6      0.0   1   5  0.0},\n",
              "   'keywordChange': {'macro_f1': 0.0,\n",
              "    'scores':         tp  fn  fp   f1\n",
              "    class                  \n",
              "    1      0.0   0   6  0.0\n",
              "    2      0.0   1   3  0.0\n",
              "    3      0.0   0   1  0.0\n",
              "    5      0.0   1   0  0.0\n",
              "    6      0.0   1   6  0.0},\n",
              "   'spellingError': {'macro_f1': 0.1,\n",
              "    'scores':         tp   fn  fp   f1\n",
              "    class                   \n",
              "    1      0.0  0.0   1  0.0\n",
              "    2      0.0  1.0   2  0.0\n",
              "    3      0.0  0.0   3  0.0\n",
              "    5      0.0  1.0   0  0.0\n",
              "    6      1.0  0.0   2  0.5},\n",
              "   'antonym': {'macro_f1': 0.26666666666666666,\n",
              "    'scores':         tp   fn   fp        f1\n",
              "    class                         \n",
              "    1      0.0  0.0  2.0  0.000000\n",
              "    2      1.0  0.0  1.0  0.666667\n",
              "    3      0.0  0.0  1.0  0.000000\n",
              "    5      0.0  1.0  0.0  0.000000\n",
              "    6      1.0  0.0  1.0  0.666667}},\n",
              "  'other': {'core': {'macro_f1': 0.10822510822510822,\n",
              "    'scores':         tp  fn   fp        f1\n",
              "    class                        \n",
              "    0      0.0  13  9.0  0.000000\n",
              "    1      0.0   0  2.0  0.000000\n",
              "    2      1.0   3  2.0  0.285714\n",
              "    3      2.0   5  2.0  0.363636\n",
              "    6      0.0   0  4.0  0.000000\n",
              "    7      0.0   0  2.0  0.000000},\n",
              "   'custom_fillers': {'macro_f1': 0.08971153846153847,\n",
              "    'scores':         tp  fn  fp        f1\n",
              "    class                       \n",
              "    0      2.0  11  10  0.160000\n",
              "    1      0.0   0   2  0.000000\n",
              "    2      1.0   3   3  0.250000\n",
              "    3      2.0   5   4  0.307692\n",
              "    4      0.0   0   1  0.000000\n",
              "    5      0.0   0   1  0.000000\n",
              "    6      0.0   0   5  0.000000\n",
              "    7      0.0   0   2  0.000000},\n",
              "   'synonym': {'macro_f1': 0.08095238095238096,\n",
              "    'scores':         tp  fn   fp        f1\n",
              "    class                        \n",
              "    0      0.0  13  5.0  0.000000\n",
              "    1      0.0   0  2.0  0.000000\n",
              "    2      1.0   3  2.0  0.285714\n",
              "    3      1.0   6  2.0  0.200000\n",
              "    6      0.0   0  3.0  0.000000\n",
              "    7      0.0   0  2.0  0.000000},\n",
              "   'keywordChange': {'macro_f1': 0.10822510822510822,\n",
              "    'scores':         tp  fn   fp        f1\n",
              "    class                        \n",
              "    0      0.0  13  9.0  0.000000\n",
              "    1      0.0   0  2.0  0.000000\n",
              "    2      1.0   3  2.0  0.285714\n",
              "    3      2.0   5  2.0  0.363636\n",
              "    6      0.0   0  4.0  0.000000\n",
              "    7      0.0   0  2.0  0.000000},\n",
              "   'spellingError': {'macro_f1': 0.11599511599511599,\n",
              "    'scores':         tp  fn    fp        f1\n",
              "    class                         \n",
              "    0      1.0  12  12.0  0.076923\n",
              "    1      0.0   0   2.0  0.000000\n",
              "    2      1.0   3   2.0  0.285714\n",
              "    3      2.0   5   3.0  0.333333\n",
              "    6      0.0   0   4.0  0.000000\n",
              "    7      0.0   0   2.0  0.000000},\n",
              "   'antonym': {'macro_f1': 0.1717171717171717,\n",
              "    'scores':         tp  fn    fp        f1\n",
              "    class                         \n",
              "    0      0.0  13  10.0  0.000000\n",
              "    1      0.0   0   2.0  0.000000\n",
              "    2      2.0   2   0.0  0.666667\n",
              "    3      2.0   5   2.0  0.363636\n",
              "    6      0.0   0   4.0  0.000000\n",
              "    7      0.0   0   2.0  0.000000}}},\n",
              " '822596.undefined': {'self': {'core': {'macro_f1': 0.4952380952380952,\n",
              "    'scores':         tp   fn   fp        f1\n",
              "    class                         \n",
              "    0      0.0  2.0  8.0  0.000000\n",
              "    1      2.0  0.0  0.0  1.000000\n",
              "    2      2.0  0.0  0.0  1.000000\n",
              "    3      4.0  3.0  4.0  0.533333\n",
              "    4      0.0  0.0  1.0  0.000000\n",
              "    6      4.0  1.0  6.0  0.533333\n",
              "    7      1.0  1.0  2.0  0.400000},\n",
              "   'custom_fillers': {'macro_f1': 0.0,\n",
              "    'scores':         tp  fn  fp   f1\n",
              "    class                  \n",
              "    0      0.0   0   1  0.0\n",
              "    1      0.0   0   2  0.0\n",
              "    2      0.0   1   2  0.0\n",
              "    3      0.0   0   3  0.0\n",
              "    5      0.0   1   0  0.0\n",
              "    6      0.0   1   3  0.0},\n",
              "   'synonym': {'macro_f1': 0.0,\n",
              "    'scores':         tp  fn  fp   f1\n",
              "    class                  \n",
              "    1      0.0   0   2  0.0\n",
              "    2      0.0   1   1  0.0\n",
              "    3      0.0   0   2  0.0\n",
              "    5      0.0   1   0  0.0\n",
              "    6      0.0   1   3  0.0},\n",
              "   'keywordChange': {'macro_f1': 0.0,\n",
              "    'scores':         tp  fn  fp   f1\n",
              "    class                  \n",
              "    1      0.0   0   5  0.0\n",
              "    2      0.0   1   3  0.0\n",
              "    3      0.0   0   3  0.0\n",
              "    5      0.0   1   0  0.0\n",
              "    6      0.0   1   3  0.0},\n",
              "   'spellingError': {'macro_f1': 0.0,\n",
              "    'scores':         tp  fn  fp   f1\n",
              "    class                  \n",
              "    1      0.0   0   2  0.0\n",
              "    2      0.0   1   1  0.0\n",
              "    3      0.0   0   3  0.0\n",
              "    5      0.0   1   0  0.0\n",
              "    6      0.0   1   3  0.0},\n",
              "   'antonym': {'macro_f1': 0.0,\n",
              "    'scores':         tp  fn  fp   f1\n",
              "    class                  \n",
              "    1      0.0   0   1  0.0\n",
              "    2      0.0   1   2  0.0\n",
              "    3      0.0   0   8  0.0\n",
              "    5      0.0   1   0  0.0\n",
              "    6      0.0   1   7  0.0}},\n",
              "  'other': {'core': {'macro_f1': 0.1111111111111111,\n",
              "    'scores':         tp  fn   fp        f1\n",
              "    class                        \n",
              "    0      0.0  13  5.0  0.000000\n",
              "    1      0.0   0  2.0  0.000000\n",
              "    2      1.0   3  1.0  0.333333\n",
              "    3      2.0   5  3.0  0.333333\n",
              "    6      0.0   0  5.0  0.000000\n",
              "    7      0.0   0  2.0  0.000000},\n",
              "   'custom_fillers': {'macro_f1': 0.12198912198912198,\n",
              "    'scores':         tp  fn   fp        f1\n",
              "    class                        \n",
              "    0      1.0  12  8.0  0.090909\n",
              "    1      0.0   0  1.0  0.000000\n",
              "    2      1.0   3  1.0  0.333333\n",
              "    3      2.0   5  4.0  0.307692\n",
              "    6      0.0   0  5.0  0.000000\n",
              "    7      0.0   0  2.0  0.000000},\n",
              "   'synonym': {'macro_f1': 0.14285714285714285,\n",
              "    'scores':         tp  fn    fp        f1\n",
              "    class                         \n",
              "    0      0.0  13  10.0  0.000000\n",
              "    1      0.0   0   2.0  0.000000\n",
              "    2      2.0   2   0.0  0.666667\n",
              "    3      2.0   5   3.0  0.333333\n",
              "    4      0.0   0   1.0  0.000000\n",
              "    6      0.0   0   6.0  0.000000\n",
              "    7      0.0   0   2.0  0.000000},\n",
              "   'keywordChange': {'macro_f1': 0.15079365079365079,\n",
              "    'scores':         tp  fn   fp        f1\n",
              "    class                        \n",
              "    0      0.0  13  5.0  0.000000\n",
              "    1      0.0   0  3.0  0.000000\n",
              "    2      2.0   2  1.0  0.571429\n",
              "    3      2.0   5  3.0  0.333333\n",
              "    6      0.0   0  5.0  0.000000\n",
              "    7      0.0   0  2.0  0.000000},\n",
              "   'spellingError': {'macro_f1': 0.11352126134734832,\n",
              "    'scores':         tp  fn   fp        f1\n",
              "    class                        \n",
              "    0      1.0  12  9.0  0.086957\n",
              "    1      0.0   0  2.0  0.000000\n",
              "    2      2.0   2  4.0  0.400000\n",
              "    3      2.0   5  4.0  0.307692\n",
              "    4      0.0   0  1.0  0.000000\n",
              "    6      0.0   0  5.0  0.000000\n",
              "    7      0.0   0  4.0  0.000000},\n",
              "   'antonym': {'macro_f1': 0.16666666666666666,\n",
              "    'scores':         tp  fn   fp        f1\n",
              "    class                        \n",
              "    0      0.0  13  6.0  0.000000\n",
              "    1      0.0   0  2.0  0.000000\n",
              "    2      2.0   2  0.0  0.666667\n",
              "    3      2.0   5  3.0  0.333333\n",
              "    6      0.0   0  5.0  0.000000\n",
              "    7      0.0   0  2.0  0.000000}}},\n",
              " '820987.undefined': {'self': {'core': {'macro_f1': 0.7949423247559894,\n",
              "    'scores':        tp   fn   fp        f1\n",
              "    class                        \n",
              "    0      16  9.0  8.0  0.653061\n",
              "    1       3  1.0  0.0  0.857143\n",
              "    2       6  1.0  2.0  0.800000\n",
              "    3      10  2.0  1.0  0.869565},\n",
              "   'custom_fillers': {'macro_f1': 0.5666214177978883,\n",
              "    'scores':        tp    fn    fp        f1\n",
              "    class                          \n",
              "    0       9  16.0  16.0  0.360000\n",
              "    1       3   1.0   2.0  0.666667\n",
              "    2       4   3.0   6.0  0.470588\n",
              "    3      10   2.0   4.0  0.769231},\n",
              "   'synonym': {'macro_f1': 0.6559658283603297,\n",
              "    'scores':        tp    fn    fp        f1\n",
              "    class                          \n",
              "    0      15  10.0  11.0  0.588235\n",
              "    1       4   0.0   1.0  0.888889\n",
              "    2       5   2.0   4.0  0.625000\n",
              "    3       6   6.0   5.0  0.521739},\n",
              "   'keywordChange': {'macro_f1': 0.7949423247559894,\n",
              "    'scores':        tp   fn   fp        f1\n",
              "    class                        \n",
              "    0      16  9.0  8.0  0.653061\n",
              "    1       3  1.0  0.0  0.857143\n",
              "    2       6  1.0  2.0  0.800000\n",
              "    3      10  2.0  1.0  0.869565},\n",
              "   'spellingError': {'macro_f1': 0.636356100795756,\n",
              "    'scores':        tp   fn   fp        f1\n",
              "    class                        \n",
              "    0      19  6.0  8.0  0.730769\n",
              "    1       3  1.0  1.0  0.750000\n",
              "    2       3  4.0  6.0  0.375000\n",
              "    3      10  2.0  7.0  0.689655},\n",
              "   'antonym': {'macro_f1': 0.6669501133786848,\n",
              "    'scores':        tp    fn   fp        f1\n",
              "    class                         \n",
              "    0      15  10.0  9.0  0.612245\n",
              "    1       3   1.0  1.0  0.750000\n",
              "    2       5   2.0  6.0  0.555556\n",
              "    3       9   3.0  3.0  0.750000}},\n",
              "  'other': {'core': {'macro_f1': 0.03225806451612903,\n",
              "    'scores':         tp  fn  fp        f1\n",
              "    class                       \n",
              "    0      2.0   7  20  0.129032\n",
              "    1      0.0   2   1  0.000000\n",
              "    2      0.0   7   3  0.000000\n",
              "    3      0.0   0  17  0.000000},\n",
              "   'custom_fillers': {'macro_f1': 0.05,\n",
              "    'scores':         tp   fn  fp   f1\n",
              "    class                   \n",
              "    0      1.0  1.0   7  0.2\n",
              "    1      0.0  1.0   1  0.0\n",
              "    2      0.0  0.0   2  0.0\n",
              "    3      0.0  0.0   4  0.0},\n",
              "   'synonym': {'macro_f1': 0.0,\n",
              "    'scores':         tp  fn  fp   f1\n",
              "    class                  \n",
              "    0      0.0   2  13  0.0\n",
              "    1      0.0   1   5  0.0\n",
              "    2      0.0   0   4  0.0\n",
              "    3      0.0   0   2  0.0},\n",
              "   'keywordChange': {'macro_f1': 0.041666666666666664,\n",
              "    'scores':         tp   fn  fp        f1\n",
              "    class                        \n",
              "    0      1.0  1.0   9  0.166667\n",
              "    1      0.0  1.0   0  0.000000\n",
              "    2      0.0  0.0   5  0.000000\n",
              "    3      0.0  0.0   4  0.000000},\n",
              "   'spellingError': {'macro_f1': 0.0625,\n",
              "    'scores':         tp   fn  fp    f1\n",
              "    class                    \n",
              "    0      1.0  1.0   5  0.25\n",
              "    1      0.0  1.0   0  0.00\n",
              "    2      0.0  0.0   3  0.00\n",
              "    3      0.0  0.0   2  0.00},\n",
              "   'antonym': {'macro_f1': 0.0,\n",
              "    'scores':         tp  fn  fp   f1\n",
              "    class                  \n",
              "    0      0.0   2   7  0.0\n",
              "    1      0.0   1   1  0.0\n",
              "    2      0.0   0   3  0.0\n",
              "    3      0.0   0   1  0.0}}},\n",
              " '820962.undefined': {'self': {'core': {'macro_f1': 0.33511904761904765,\n",
              "    'scores':         tp   fn   fp        f1\n",
              "    class                         \n",
              "    0      0.0  2.0  4.0  0.000000\n",
              "    1      1.0  1.0  2.0  0.400000\n",
              "    2      1.0  1.0  1.0  0.500000\n",
              "    3      5.0  2.0  2.0  0.714286\n",
              "    4      0.0  0.0  1.0  0.000000\n",
              "    5      0.0  0.0  1.0  0.000000\n",
              "    6      4.0  1.0  3.0  0.666667\n",
              "    7      1.0  1.0  2.0  0.400000},\n",
              "   'custom_fillers': {'macro_f1': 0.16666666666666666,\n",
              "    'scores':         tp   fn   fp   f1\n",
              "    class                    \n",
              "    0      0.0  0.0  2.0  0.0\n",
              "    1      0.0  0.0  2.0  0.0\n",
              "    2      1.0  0.0  0.0  1.0\n",
              "    3      0.0  0.0  4.0  0.0\n",
              "    5      0.0  1.0  0.0  0.0\n",
              "    6      0.0  1.0  3.0  0.0},\n",
              "   'synonym': {'macro_f1': 0.12380952380952381,\n",
              "    'scores':         tp   fn  fp        f1\n",
              "    class                        \n",
              "    1      0.0  0.0   4  0.000000\n",
              "    2      1.0  0.0   5  0.285714\n",
              "    3      0.0  0.0   5  0.000000\n",
              "    5      0.0  1.0   0  0.000000\n",
              "    6      1.0  0.0   4  0.333333},\n",
              "   'keywordChange': {'macro_f1': 0.13333333333333333,\n",
              "    'scores':         tp   fn   fp        f1\n",
              "    class                         \n",
              "    1      0.0  0.0  2.0  0.000000\n",
              "    2      1.0  0.0  1.0  0.666667\n",
              "    3      0.0  0.0  4.0  0.000000\n",
              "    5      0.0  1.0  0.0  0.000000\n",
              "    6      0.0  1.0  5.0  0.000000},\n",
              "   'spellingError': {'macro_f1': 0.21333333333333332,\n",
              "    'scores':         tp   fn   fp        f1\n",
              "    class                         \n",
              "    1      0.0  0.0  1.0  0.000000\n",
              "    2      1.0  0.0  1.0  0.666667\n",
              "    3      0.0  0.0  2.0  0.000000\n",
              "    5      0.0  1.0  0.0  0.000000\n",
              "    6      1.0  0.0  3.0  0.400000},\n",
              "   'antonym': {'macro_f1': 0.0,\n",
              "    'scores':         tp  fn  fp   f1\n",
              "    class                  \n",
              "    1      0.0   0   2  0.0\n",
              "    2      0.0   1   3  0.0\n",
              "    3      0.0   0   3  0.0\n",
              "    5      0.0   1   0  0.0\n",
              "    6      0.0   1   6  0.0\n",
              "    7      0.0   0   2  0.0}},\n",
              "  'other': {'core': {'macro_f1': 0.0989010989010989,\n",
              "    'scores':         tp  fn   fp        f1\n",
              "    class                        \n",
              "    0      0.0  13  9.0  0.000000\n",
              "    1      0.0   0  3.0  0.000000\n",
              "    2      1.0   3  2.0  0.285714\n",
              "    3      2.0   5  4.0  0.307692\n",
              "    6      0.0   0  4.0  0.000000\n",
              "    7      0.0   0  2.0  0.000000},\n",
              "   'custom_fillers': {'macro_f1': 0.05833333333333333,\n",
              "    'scores':         tp  fn  fp        f1\n",
              "    class                       \n",
              "    0      1.0  12  10  0.083333\n",
              "    1      0.0   0   2  0.000000\n",
              "    2      0.0   4   3  0.000000\n",
              "    3      2.0   5   6  0.266667\n",
              "    6      0.0   0   6  0.000000\n",
              "    7      0.0   0   2  0.000000},\n",
              "   'synonym': {'macro_f1': 0.0861111111111111,\n",
              "    'scores':         tp  fn   fp        f1\n",
              "    class                        \n",
              "    0      0.0  13  5.0  0.000000\n",
              "    1      0.0   0  2.0  0.000000\n",
              "    2      1.0   3  3.0  0.250000\n",
              "    3      2.0   5  6.0  0.266667\n",
              "    6      0.0   0  5.0  0.000000\n",
              "    7      0.0   0  2.0  0.000000},\n",
              "   'keywordChange': {'macro_f1': 0.0989010989010989,\n",
              "    'scores':         tp  fn   fp        f1\n",
              "    class                        \n",
              "    0      0.0  13  9.0  0.000000\n",
              "    1      0.0   0  3.0  0.000000\n",
              "    2      1.0   3  2.0  0.285714\n",
              "    3      2.0   5  4.0  0.307692\n",
              "    6      0.0   0  4.0  0.000000\n",
              "    7      0.0   0  2.0  0.000000},\n",
              "   'spellingError': {'macro_f1': 0.13766233766233765,\n",
              "    'scores':         tp    fn    fp        f1\n",
              "    class                           \n",
              "    0      0.0  13.0  10.0  0.000000\n",
              "    1      0.0   0.0   2.0  0.000000\n",
              "    2      3.0   1.0   3.0  0.600000\n",
              "    3      2.0   5.0   2.0  0.363636\n",
              "    4      0.0   0.0   3.0  0.000000\n",
              "    6      0.0   0.0   4.0  0.000000\n",
              "    7      0.0   0.0   2.0  0.000000},\n",
              "   'antonym': {'macro_f1': 0.14393939393939395,\n",
              "    'scores':         tp  fn   fp        f1\n",
              "    class                        \n",
              "    0      0.0  13  9.0  0.000000\n",
              "    1      0.0   0  4.0  0.000000\n",
              "    2      2.0   2  2.0  0.500000\n",
              "    3      2.0   5  2.0  0.363636\n",
              "    6      0.0   0  4.0  0.000000\n",
              "    7      0.0   0  2.0  0.000000}}},\n",
              " '820965.undefined': {'self': {'core': {'macro_f1': 0.37576312576312576,\n",
              "    'scores':         tp   fn   fp        f1\n",
              "    class                         \n",
              "    0      0.0  2.0  3.0  0.000000\n",
              "    1      1.0  1.0  5.0  0.250000\n",
              "    2      1.0  1.0  0.0  0.666667\n",
              "    3      4.0  3.0  7.0  0.444444\n",
              "    4      0.0  0.0  2.0  0.000000\n",
              "    6      5.0  0.0  3.0  0.769231\n",
              "    7      1.0  1.0  1.0  0.500000},\n",
              "   'custom_fillers': {'macro_f1': 0.0,\n",
              "    'scores':         tp  fn  fp   f1\n",
              "    class                  \n",
              "    0      0.0   0   7  0.0\n",
              "    1      0.0   0   1  0.0\n",
              "    2      0.0   1   5  0.0\n",
              "    3      0.0   0   9  0.0\n",
              "    5      0.0   1   2  0.0\n",
              "    6      0.0   1   9  0.0\n",
              "    7      0.0   0   2  0.0},\n",
              "   'synonym': {'macro_f1': 0.0,\n",
              "    'scores':         tp  fn  fp   f1\n",
              "    class                  \n",
              "    0      0.0   0   1  0.0\n",
              "    1      0.0   0   4  0.0\n",
              "    2      0.0   1   3  0.0\n",
              "    3      0.0   0   6  0.0\n",
              "    5      0.0   1   0  0.0\n",
              "    6      0.0   1   9  0.0},\n",
              "   'keywordChange': {'macro_f1': 0.0,\n",
              "    'scores':         tp  fn  fp   f1\n",
              "    class                  \n",
              "    1      0.0   0   3  0.0\n",
              "    2      0.0   1   2  0.0\n",
              "    3      0.0   0   3  0.0\n",
              "    5      0.0   1   0  0.0\n",
              "    6      0.0   1   6  0.0\n",
              "    7      0.0   0   1  0.0},\n",
              "   'spellingError': {'macro_f1': 0.05555555555555555,\n",
              "    'scores':         tp   fn  fp        f1\n",
              "    class                        \n",
              "    1      0.0  0.0   3  0.000000\n",
              "    2      0.0  1.0   7  0.000000\n",
              "    3      0.0  0.0   3  0.000000\n",
              "    5      0.0  1.0   0  0.000000\n",
              "    6      1.0  0.0   4  0.333333\n",
              "    7      0.0  0.0   4  0.000000},\n",
              "   'antonym': {'macro_f1': 0.0,\n",
              "    'scores':         tp  fn  fp   f1\n",
              "    class                  \n",
              "    0      0.0   0   1  0.0\n",
              "    1      0.0   0   9  0.0\n",
              "    2      0.0   1   4  0.0\n",
              "    3      0.0   0   3  0.0\n",
              "    5      0.0   1   1  0.0\n",
              "    6      0.0   1   3  0.0\n",
              "    7      0.0   0   2  0.0}},\n",
              "  'other': {'core': {'macro_f1': 0.10317460317460318,\n",
              "    'scores':         tp  fn    fp        f1\n",
              "    class                         \n",
              "    0      0.0  13  10.0  0.000000\n",
              "    1      0.0   0   2.0  0.000000\n",
              "    2      1.0   3   1.0  0.333333\n",
              "    3      2.0   5   5.0  0.285714\n",
              "    6      0.0   0   6.0  0.000000\n",
              "    7      0.0   0   2.0  0.000000},\n",
              "   'custom_fillers': {'macro_f1': 0.06043956043956044,\n",
              "    'scores':         tp  fn  fp        f1\n",
              "    class                       \n",
              "    0      1.0  12  12  0.076923\n",
              "    1      0.0   0   1  0.000000\n",
              "    2      0.0   4   2  0.000000\n",
              "    3      2.0   5   5  0.285714\n",
              "    6      0.0   0   7  0.000000\n",
              "    7      0.0   0   2  0.000000},\n",
              "   'synonym': {'macro_f1': 0.07539682539682539,\n",
              "    'scores':         tp  fn   fp        f1\n",
              "    class                        \n",
              "    0      0.0  13  7.0  0.000000\n",
              "    1      0.0   0  3.0  0.000000\n",
              "    2      1.0   3  2.0  0.285714\n",
              "    3      1.0   6  4.0  0.166667\n",
              "    6      0.0   0  6.0  0.000000\n",
              "    7      0.0   0  2.0  0.000000},\n",
              "   'keywordChange': {'macro_f1': 0.09999999999999999,\n",
              "    'scores':         tp  fn    fp        f1\n",
              "    class                         \n",
              "    0      0.0  13  11.0  0.000000\n",
              "    1      0.0   0   2.0  0.000000\n",
              "    2      1.0   3   1.0  0.333333\n",
              "    3      2.0   5   6.0  0.266667\n",
              "    6      0.0   0   6.0  0.000000\n",
              "    7      0.0   0   2.0  0.000000},\n",
              "   'spellingError': {'macro_f1': 0.18686868686868685,\n",
              "    'scores':         tp  fn   fp        f1\n",
              "    class                        \n",
              "    0      1.0  12  8.0  0.090909\n",
              "    1      0.0   0  2.0  0.000000\n",
              "    2      2.0   2  0.0  0.666667\n",
              "    3      2.0   5  2.0  0.363636\n",
              "    6      0.0   0  4.0  0.000000\n",
              "    7      0.0   0  2.0  0.000000},\n",
              "   'antonym': {'macro_f1': 0.08333333333333333,\n",
              "    'scores':         tp  fn    fp    f1\n",
              "    class                     \n",
              "    0      0.0  13  14.0  0.00\n",
              "    1      0.0   0   2.0  0.00\n",
              "    2      1.0   3   3.0  0.25\n",
              "    3      2.0   5   7.0  0.25\n",
              "    6      0.0   0   5.0  0.00\n",
              "    7      0.0   0   2.0  0.00}}},\n",
              " '820986.undefined': {'self': {'core': {'macro_f1': 0.8851208961845608,\n",
              "    'scores':        tp   fn   fp        f1\n",
              "    class                        \n",
              "    0      23  2.0  1.0  0.938776\n",
              "    1       3  1.0  0.0  0.857143\n",
              "    2       7  0.0  2.0  0.875000\n",
              "    3      10  2.0  1.0  0.869565},\n",
              "   'custom_fillers': {'macro_f1': 0.7161239495798319,\n",
              "    'scores':        tp    fn    fp        f1\n",
              "    class                          \n",
              "    0      14  11.0  12.0  0.549020\n",
              "    1       3   1.0   0.0  0.857143\n",
              "    2       5   2.0   4.0  0.625000\n",
              "    3      10   2.0   2.0  0.833333},\n",
              "   'synonym': {'macro_f1': 0.6855602240896359,\n",
              "    'scores':        tp   fn   fp        f1\n",
              "    class                        \n",
              "    0      19  6.0  7.0  0.745098\n",
              "    1       3  1.0  0.0  0.857143\n",
              "    2       4  3.0  5.0  0.500000\n",
              "    3       8  4.0  5.0  0.640000},\n",
              "   'keywordChange': {'macro_f1': 0.8427871148459384,\n",
              "    'scores':        tp   fn   fp        f1\n",
              "    class                        \n",
              "    0      21  4.0  3.0  0.857143\n",
              "    1       3  1.0  0.0  0.857143\n",
              "    2       7  0.0  3.0  0.823529\n",
              "    3      10  2.0  2.0  0.833333},\n",
              "   'spellingError': {'macro_f1': 0.5,\n",
              "    'scores':          tp  fn    fp        f1\n",
              "    class                          \n",
              "    0      17.0   8   9.0  0.666667\n",
              "    1       1.0   3   2.0  0.285714\n",
              "    2       4.0   3  10.0  0.380952\n",
              "    3       9.0   3   6.0  0.666667},\n",
              "   'antonym': {'macro_f1': 0.7674378881987578,\n",
              "    'scores':        tp   fn   fp        f1\n",
              "    class                        \n",
              "    0      17  8.0  8.0  0.680000\n",
              "    1       3  1.0  0.0  0.857143\n",
              "    2       6  1.0  3.0  0.750000\n",
              "    3       9  3.0  2.0  0.782609}},\n",
              "  'other': {'core': {'macro_f1': 0.027777777777777776,\n",
              "    'scores':         tp  fn  fp        f1\n",
              "    class                       \n",
              "    0      1.0   8   8  0.111111\n",
              "    1      0.0   2   1  0.000000\n",
              "    2      0.0   7   0  0.000000\n",
              "    3      0.0   0   6  0.000000},\n",
              "   'custom_fillers': {'macro_f1': 0.1111111111111111,\n",
              "    'scores':         tp   fn  fp        f1\n",
              "    class                        \n",
              "    0      1.0  1.0   3  0.333333\n",
              "    1      0.0  1.0   0  0.000000\n",
              "    2      0.0  0.0   2  0.000000},\n",
              "   'synonym': {'macro_f1': 0.1111111111111111,\n",
              "    'scores':         tp   fn  fp        f1\n",
              "    class                        \n",
              "    0      1.0  1.0   3  0.333333\n",
              "    1      0.0  1.0   0  0.000000\n",
              "    2      0.0  0.0   2  0.000000},\n",
              "   'keywordChange': {'macro_f1': 0.13333333333333333,\n",
              "    'scores':         tp   fn  fp   f1\n",
              "    class                   \n",
              "    0      1.0  1.0   2  0.4\n",
              "    1      0.0  1.0   0  0.0\n",
              "    2      0.0  0.0   1  0.0},\n",
              "   'spellingError': {'macro_f1': 0.19047619047619047,\n",
              "    'scores':         tp   fn  fp        f1\n",
              "    class                        \n",
              "    0      2.0  0.0   3  0.571429\n",
              "    1      0.0  1.0   0  0.000000\n",
              "    2      0.0  0.0   3  0.000000},\n",
              "   'antonym': {'macro_f1': 0.0,\n",
              "    'scores':         tp  fn  fp   f1\n",
              "    class                  \n",
              "    0      0.0   2   4  0.0\n",
              "    1      0.0   1   0  0.0\n",
              "    2      0.0   0   2  0.0}}}}"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "RESULTS"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for model in CONFIG_MAP:\n",
        "  if CONFIG_MAP[model].get('dataset') == 'TUDarmstadt':\n",
        "    strategy = CONFIG_MAP[model].get('strat')\n",
        "    Processor = CONFIG_MAP[model].get('processor')\n",
        "    dataset = CONFIG_MAP[model].get('dataset')\n",
        "    print(\n",
        "            f'{dataset}->{model_name_decoded}->{strategy} at PATH: {model_path}'\n",
        "        )\n",
        "    print('=================================================================================')\n",
        "        \n",
        "    results_self = RESULTS[model]['self']\n",
        "    for attack in results_self:\n",
        "      print(f'{attack}-------------------------------------------------------------------------------')\n",
        "      for metric, val in results_self[attack]['avgs'].items():\n",
        "        print(f'{metric}: {val}')\n",
        "      print(results_self[attack]['scores'])\n",
        "      print('\\n\\n\\n')"
      ],
      "metadata": {
        "id": "BEchJYt0OblS",
        "outputId": "13aa08f5-559c-41df-8153-afd082519b99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "BEchJYt0OblS",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TUDarmstadt->roberta-base->bieo at PATH: drive/MyDrive/Desktop/tmpdir/job/822594.undefined/models/cm9iZXJ0YS1iYXNlX2ZpbmFs\n",
            "=================================================================================\n",
            "core-------------------------------------------------------------------------------\n",
            "f1: 0.7079025125846855\n",
            "recall: 0.7373476287271112\n",
            "precision: 0.6812618396866449\n",
            "        tp   fn   fp        f1    recall  precision\n",
            "class                                              \n",
            "0      920  426  438  0.680473  0.683507   0.677467\n",
            "1      121   32   51  0.744615  0.790850   0.703488\n",
            "2      188  116  145  0.590267  0.618421   0.564565\n",
            "3      693  116  196  0.816254  0.856613   0.779528\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "custom_fillers-------------------------------------------------------------------------------\n",
            "f1: 0.40157620191896376\n",
            "recall: 0.43058029733586756\n",
            "precision: 0.37939143515073415\n",
            "        tp   fn    fp        f1    recall  precision\n",
            "class                                               \n",
            "0      384  962  1053  0.275961  0.285290   0.267223\n",
            "1       63   90    81  0.424242  0.411765   0.437500\n",
            "2      102  202   314  0.283333  0.335526   0.245192\n",
            "3      558  251   425  0.622768  0.689740   0.567650\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "synonym-------------------------------------------------------------------------------\n",
            "f1: 0.6517002531321003\n",
            "recall: 0.6863005837508649\n",
            "precision: 0.6213351949487775\n",
            "        tp   fn   fp        f1    recall  precision\n",
            "class                                              \n",
            "0      852  494  517  0.627624  0.632987   0.622352\n",
            "1      108   45   60  0.672897  0.705882   0.642857\n",
            "2      172  132  193  0.514200  0.565789   0.471233\n",
            "3      680  129  228  0.792079  0.840544   0.748899\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "spellingError-------------------------------------------------------------------------------\n",
            "f1: 0.569035030183861\n",
            "recall: 0.6020311836052029\n",
            "precision: 0.545325342793433\n",
            "        tp   fn   fp        f1    recall  precision\n",
            "class                                              \n",
            "0      755  591  614  0.556169  0.560921   0.551497\n",
            "1       82   71   64  0.548495  0.535948   0.561644\n",
            "2      157  147  294  0.415894  0.516447   0.348115\n",
            "3      643  166  250  0.755582  0.794808   0.720045\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "keywordChange-------------------------------------------------------------------------------\n",
            "f1: 0.6881966788915412\n",
            "recall: 0.7211108703496987\n",
            "precision: 0.6591691337229617\n",
            "        tp   fn   fp        f1    recall  precision\n",
            "class                                              \n",
            "0      933  413  424  0.690344  0.693165   0.687546\n",
            "1      116   37   65  0.694611  0.758170   0.640884\n",
            "2      173  131  159  0.544025  0.569079   0.521084\n",
            "3      699  110  189  0.823807  0.864030   0.787162\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "antonym-------------------------------------------------------------------------------\n",
            "f1: 0.7011843495785042\n",
            "recall: 0.7306075200566282\n",
            "precision: 0.674604909190567\n",
            "        tp   fn   fp        f1    recall  precision\n",
            "class                                              \n",
            "0      922  424  450  0.678440  0.684993   0.672012\n",
            "1      114   39   61  0.695122  0.745098   0.651429\n",
            "2      188  116  148  0.587500  0.618421   0.559524\n",
            "3      707  102  160  0.843675  0.873918   0.815456\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TUDarmstadt->roberta-base->bio at PATH: drive/MyDrive/Desktop/tmpdir/job/822594.undefined/models/cm9iZXJ0YS1iYXNlX2ZpbmFs\n",
            "=================================================================================\n",
            "core-------------------------------------------------------------------------------\n",
            "f1: 0.7619653760422207\n",
            "recall: 0.7861212983445895\n",
            "precision: 0.7424143901358423\n",
            "         tp   fn   fp        f1    recall  precision\n",
            "class                                               \n",
            "0      1050  296  304  0.777778  0.780089   0.775480\n",
            "1       125   28   28  0.816993  0.816993   0.816993\n",
            "2       210   94  178  0.606936  0.690789   0.541237\n",
            "3       693  116  136  0.846154  0.856613   0.835947\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "antonym-------------------------------------------------------------------------------\n",
            "f1: 0.6949821348423602\n",
            "recall: 0.7364956471763434\n",
            "precision: 0.660856656274363\n",
            "        tp   fn   fp        f1    recall  precision\n",
            "class                                              \n",
            "0      918  428  452  0.675994  0.682021   0.670073\n",
            "1      117   36   56  0.717791  0.764706   0.676301\n",
            "2      201  103  203  0.567797  0.661184   0.497525\n",
            "3      678  131  170  0.818346  0.838072   0.799528\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "synonym-------------------------------------------------------------------------------\n",
            "f1: 0.6978734515250135\n",
            "recall: 0.7302656645402699\n",
            "precision: 0.6699484173907224\n",
            "        tp   fn   fp        f1    recall  precision\n",
            "class                                              \n",
            "0      933  413  438  0.686787  0.693165   0.680525\n",
            "1      123   30   41  0.776025  0.803922   0.750000\n",
            "2      183  121  200  0.532751  0.601974   0.477807\n",
            "3      665  144  197  0.795931  0.822002   0.771462\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "keywordChange-------------------------------------------------------------------------------\n",
            "f1: 0.7633062586347035\n",
            "recall: 0.7899849573977475\n",
            "precision: 0.7403245114559069\n",
            "         tp   fn   fp        f1    recall  precision\n",
            "class                                               \n",
            "0      1047  299  320  0.771839  0.777860   0.765911\n",
            "1       125   28   37  0.793651  0.816993   0.771605\n",
            "2       215   89  158  0.635155  0.707237   0.576408\n",
            "3       694  115  125  0.852580  0.857849   0.847375\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "custom_fillers-------------------------------------------------------------------------------\n",
            "f1: 0.4477515230822147\n",
            "recall: 0.47855991406761955\n",
            "precision: 0.42566530957548077\n",
            "        tp   fn   fp        f1    recall  precision\n",
            "class                                              \n",
            "0      448  898  965  0.324755  0.332838   0.317056\n",
            "1       72   81   73  0.483221  0.470588   0.496552\n",
            "2      125  179  336  0.326797  0.411184   0.271150\n",
            "3      566  243  350  0.656232  0.699629   0.617904\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "spellingError-------------------------------------------------------------------------------\n",
            "f1: 0.5692548133538966\n",
            "recall: 0.6055721187319065\n",
            "precision: 0.5431638833309241\n",
            "        tp   fn   fp        f1    recall  precision\n",
            "class                                              \n",
            "0      738  608  646  0.540659  0.548291   0.533237\n",
            "1       88   65   65  0.575163  0.575163   0.575163\n",
            "2      166  138  298  0.432292  0.546053   0.357759\n",
            "3      609  200  253  0.728905  0.752781   0.706497\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TUDarmstadt->roberta-base->io at PATH: drive/MyDrive/Desktop/tmpdir/job/822594.undefined/models/cm9iZXJ0YS1iYXNlX2ZpbmFs\n",
            "=================================================================================\n",
            "core-------------------------------------------------------------------------------\n",
            "f1: 0.6974213730656491\n",
            "recall: 0.7495661853296908\n",
            "precision: 0.655751024555878\n",
            "        tp   fn   fp        f1    recall  precision\n",
            "class                                              \n",
            "0      831  515  565  0.606127  0.617385   0.595272\n",
            "1      132   21   55  0.776471  0.862745   0.705882\n",
            "2      212   92  195  0.596343  0.697368   0.520885\n",
            "3      664  145  165  0.810745  0.820766   0.800965\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "spellingError-------------------------------------------------------------------------------\n",
            "f1: 0.5556566969586532\n",
            "recall: 0.6140840990459936\n",
            "precision: 0.5116356638564787\n",
            "        tp   fn   fp        f1    recall  precision\n",
            "class                                              \n",
            "0      626  720  789  0.453459  0.465082   0.442403\n",
            "1       97   56   95  0.562319  0.633987   0.505208\n",
            "2      177  127  282  0.463958  0.582237   0.385621\n",
            "3      627  182  252  0.742891  0.775031   0.713311\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "synonym-------------------------------------------------------------------------------\n",
            "f1: 0.6720782519157976\n",
            "recall: 0.7145759977826859\n",
            "precision: 0.6367075408834839\n",
            "        tp   fn   fp        f1    recall  precision\n",
            "class                                              \n",
            "0      841  505  554  0.613645  0.624814   0.602867\n",
            "1      126   27   61  0.741176  0.823529   0.673797\n",
            "2      184  120  194  0.539589  0.605263   0.486772\n",
            "3      651  158  180  0.793902  0.804697   0.783394\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "keywordChange-------------------------------------------------------------------------------\n",
            "f1: 0.6692685846658375\n",
            "recall: 0.7190879704729518\n",
            "precision: 0.6296268704312814\n",
            "        tp   fn   fp        f1    recall  precision\n",
            "class                                              \n",
            "0      787  559  610  0.573824  0.584695   0.563350\n",
            "1      122   31   67  0.713450  0.797386   0.645503\n",
            "2      207   97  198  0.583921  0.680921   0.511111\n",
            "3      658  151  166  0.805879  0.813350   0.798544\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "antonym-------------------------------------------------------------------------------\n",
            "f1: 0.6400301573673354\n",
            "recall: 0.6983639029587294\n",
            "precision: 0.5961202943409692\n",
            "        tp   fn   fp        f1    recall  precision\n",
            "class                                              \n",
            "0      773  573  614  0.565679  0.574294   0.557318\n",
            "1      124   29   80  0.694678  0.810458   0.607843\n",
            "2      187  117  236  0.514443  0.615132   0.442080\n",
            "3      642  167  184  0.785321  0.793572   0.777240\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "custom_fillers-------------------------------------------------------------------------------\n",
            "f1: 0.3714787301610163\n",
            "recall: 0.43162793228911\n",
            "precision: 0.3306197576887232\n",
            "        tp   fn    fp        f1    recall  precision\n",
            "class                                               \n",
            "0      352  994  1128  0.249115  0.261516   0.237838\n",
            "1       76   77   146  0.405333  0.496732   0.342342\n",
            "2      123  181   399  0.297821  0.404605   0.235632\n",
            "3      456  353   444  0.533645  0.563659   0.506667\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TUDarmstadt->roberta-base->bieo at PATH: drive/MyDrive/Desktop/tmpdir/job/822594.undefined/models/cm9iZXJ0YS1iYXNlX2ZpbmFs\n",
            "=================================================================================\n",
            "core-------------------------------------------------------------------------------\n",
            "f1: 0.7381932849862258\n",
            "recall: 0.7744244970042536\n",
            "precision: 0.7062587992240557\n",
            "        tp   fn   fp        f1    recall  precision\n",
            "class                                              \n",
            "0      970  374  397  0.715603  0.721726   0.709583\n",
            "1      135   17   42  0.820669  0.888158   0.762712\n",
            "2      187  117  164  0.570992  0.615132   0.532764\n",
            "3      706  103  155  0.845509  0.872682   0.819977\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "custom_fillers-------------------------------------------------------------------------------\n",
            "f1: 0.3018548690618212\n",
            "recall: 0.37362808549030724\n",
            "precision: 0.25465620408450135\n",
            "        tp   fn    fp        f1    recall  precision\n",
            "class                                               \n",
            "0      220  941  1164  0.172888  0.189492   0.158960\n",
            "1       58   54   115  0.407018  0.517857   0.335260\n",
            "2       70  196   404  0.189189  0.263158   0.147679\n",
            "3      382  347   632  0.438325  0.524005   0.376726\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "synonym-------------------------------------------------------------------------------\n",
            "f1: 0.6697838573999466\n",
            "recall: 0.714634918092806\n",
            "precision: 0.6316342827010537\n",
            "        tp   fn   fp        f1    recall  precision\n",
            "class                                              \n",
            "0      823  510  543  0.609856  0.617404   0.602489\n",
            "1      125   24   57  0.755287  0.838926   0.686813\n",
            "2      166  136  195  0.500754  0.549669   0.459834\n",
            "3      688  119  197  0.813239  0.852540   0.777401\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "spellingError-------------------------------------------------------------------------------\n",
            "f1: 0.5766709043839935\n",
            "recall: 0.6294270640263215\n",
            "precision: 0.5337187116146866\n",
            "        tp   fn   fp        f1    recall  precision\n",
            "class                                              \n",
            "0      691  598  667  0.522100  0.536074   0.508837\n",
            "1      102   38   64  0.666667  0.728571   0.614458\n",
            "2      132  160  269  0.380952  0.452055   0.329177\n",
            "3      636  158  296  0.736964  0.801008   0.682403\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "keywordChange-------------------------------------------------------------------------------\n",
            "f1: 0.7302706250550833\n",
            "recall: 0.7712350745119968\n",
            "precision: 0.6952851770959736\n",
            "        tp   fn   fp        f1    recall  precision\n",
            "class                                              \n",
            "0      956  387  412  0.705275  0.711839   0.698830\n",
            "1      136   16   52  0.800000  0.894737   0.723404\n",
            "2      183  121  160  0.565688  0.601974   0.533528\n",
            "3      709  100  150  0.850120  0.876391   0.825378\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "antonym-------------------------------------------------------------------------------\n",
            "f1: 0.6644195869837297\n",
            "recall: 0.7206272619192964\n",
            "precision: 0.6188242576392455\n",
            "        tp   fn   fp        f1    recall  precision\n",
            "class                                              \n",
            "0      830  509  551  0.610294  0.619866   0.601014\n",
            "1      122   29   67  0.717647  0.807947   0.645503\n",
            "2      183  121  218  0.519149  0.601974   0.456359\n",
            "3      689  119  203  0.810588  0.852723   0.772422\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TUDarmstadt->roberta-base->bio at PATH: drive/MyDrive/Desktop/tmpdir/job/822594.undefined/models/cm9iZXJ0YS1iYXNlX2ZpbmFs\n",
            "=================================================================================\n",
            "core-------------------------------------------------------------------------------\n",
            "f1: 0.7884860588949532\n",
            "recall: 0.7946477824466915\n",
            "precision: 0.7835115006989958\n",
            "         tp   fn   fp        f1    recall  precision\n",
            "class                                               \n",
            "0      1093  251  263  0.809630  0.813244   0.806047\n",
            "1       129   23   24  0.845902  0.848684   0.843137\n",
            "2       186  118   98  0.632653  0.611842   0.654930\n",
            "3       732   77  150  0.865760  0.904821   0.829932\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "antonym-------------------------------------------------------------------------------\n",
            "f1: 0.7267639838397321\n",
            "recall: 0.738969073725118\n",
            "precision: 0.7156637944878024\n",
            "        tp   fn   fp        f1    recall  precision\n",
            "class                                              \n",
            "0      920  420  434  0.682999  0.686567   0.679468\n",
            "1      121   30   29  0.803987  0.801325   0.806667\n",
            "2      175  129  132  0.572831  0.575658   0.570033\n",
            "3      721   87  173  0.847239  0.892327   0.806488\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "synonym-------------------------------------------------------------------------------\n",
            "f1: 0.6985918765087606\n",
            "recall: 0.7180660569879356\n",
            "precision: 0.6811128958684749\n",
            "        tp   fn   fp        f1    recall  precision\n",
            "class                                              \n",
            "0      890  442  462  0.663189  0.668168   0.658284\n",
            "1      119   30   36  0.782895  0.798658   0.767742\n",
            "2      155  147  145  0.514950  0.513245   0.516667\n",
            "3      720   87  201  0.833333  0.892193   0.781759\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "keywordChange-------------------------------------------------------------------------------\n",
            "f1: 0.7809613050717794\n",
            "recall: 0.7903456420785523\n",
            "precision: 0.7730720868313856\n",
            "         tp   fn   fp        f1    recall  precision\n",
            "class                                               \n",
            "0      1100  243  260  0.813910  0.819062   0.808824\n",
            "1       130   22   26  0.844156  0.855263   0.833333\n",
            "2       177  127  105  0.604096  0.582237   0.627660\n",
            "3       732   77  158  0.861683  0.904821   0.822472\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "custom_fillers-------------------------------------------------------------------------------\n",
            "f1: 0.42262949626554097\n",
            "recall: 0.46831290110391627\n",
            "precision: 0.3873663327586669\n",
            "        tp   fn   fp        f1    recall  precision\n",
            "class                                              \n",
            "0      342  810  938  0.281250  0.296875   0.267188\n",
            "1       65   49   62  0.539419  0.570175   0.511811\n",
            "2       96  168  310  0.286567  0.363636   0.236453\n",
            "3      471  262  411  0.583282  0.642565   0.534014\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "spellingError-------------------------------------------------------------------------------\n",
            "f1: 0.5711514226565039\n",
            "recall: 0.5964405094502307\n",
            "precision: 0.5536958310571539\n",
            "        tp   fn   fp        f1    recall  precision\n",
            "class                                              \n",
            "0      692  592  650  0.527037  0.538941   0.515648\n",
            "1       77   61   43  0.596899  0.557971   0.641667\n",
            "2      137  155  250  0.403535  0.469178   0.354005\n",
            "3      650  143  274  0.757135  0.819672   0.703463\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TUDarmstadt->roberta-base->io at PATH: drive/MyDrive/Desktop/tmpdir/job/822594.undefined/models/cm9iZXJ0YS1iYXNlX2ZpbmFs\n",
            "=================================================================================\n",
            "core-------------------------------------------------------------------------------\n",
            "f1: 0.7874477698063406\n",
            "recall: 0.797291932415247\n",
            "precision: 0.778764890654741\n",
            "         tp   fn   fp        f1    recall  precision\n",
            "class                                               \n",
            "0      1079  265  281  0.798077  0.802827   0.793382\n",
            "1       129   23   22  0.851485  0.848684   0.854305\n",
            "2       189  115  107  0.630000  0.621711   0.638514\n",
            "3       741   68  153  0.870229  0.915946   0.828859\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "spellingError-------------------------------------------------------------------------------\n",
            "f1: 0.5816210181066526\n",
            "recall: 0.6365550482985234\n",
            "precision: 0.5411039776205414\n",
            "        tp   fn   fp        f1    recall  precision\n",
            "class                                              \n",
            "0      667  620  681  0.506262  0.518260   0.494807\n",
            "1       89   50   63  0.611684  0.640288   0.585526\n",
            "2      173  120  293  0.455863  0.590444   0.371245\n",
            "3      633  161  255  0.752675  0.797229   0.712838\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "synonym-------------------------------------------------------------------------------\n",
            "f1: 0.7296557901513805\n",
            "recall: 0.7496697282939688\n",
            "precision: 0.7111767273215259\n",
            "        tp   fn   fp        f1    recall  precision\n",
            "class                                              \n",
            "0      954  379  408  0.707978  0.715679   0.700441\n",
            "1      122   27   29  0.813333  0.818792   0.807947\n",
            "2      172  130  155  0.546900  0.569536   0.525994\n",
            "3      722   85  169  0.850412  0.894672   0.810325\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "keywordChange-------------------------------------------------------------------------------\n",
            "f1: 0.7668585558222478\n",
            "recall: 0.7845212776663639\n",
            "precision: 0.7505925065111942\n",
            "        tp   fn   fp        f1    recall  precision\n",
            "class                                              \n",
            "0      998  345  368  0.736803  0.743112   0.730600\n",
            "1      129   23   32  0.824281  0.848684   0.801242\n",
            "2      192  112  108  0.635762  0.631579   0.640000\n",
            "3      740   69  151  0.870588  0.914710   0.830527\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "antonym-------------------------------------------------------------------------------\n",
            "f1: 0.7313651311178377\n",
            "recall: 0.7625363315175516\n",
            "precision: 0.7031963145053108\n",
            "        tp   fn   fp        f1    recall  precision\n",
            "class                                              \n",
            "0      949  388  415  0.702703  0.709798   0.695748\n",
            "1      123   28   41  0.780952  0.814570   0.750000\n",
            "2      196  108  154  0.599388  0.644737   0.560000\n",
            "3      711   96  170  0.842417  0.881041   0.807037\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "custom_fillers-------------------------------------------------------------------------------\n",
            "f1: 0.5012930805446302\n",
            "recall: 0.5508404628459567\n",
            "precision: 0.4627428201617083\n",
            "        tp   fn   fp        f1    recall  precision\n",
            "class                                              \n",
            "0      571  588  727  0.464794  0.492666   0.439908\n",
            "1       70   44   57  0.580913  0.614035   0.551181\n",
            "2      117  147  286  0.350825  0.443182   0.290323\n",
            "3      479  254  362  0.608640  0.653479   0.569560\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "7ac81730",
      "metadata": {
        "id": "7ac81730",
        "outputId": "57cf4e8b-1bd9-411a-e663-1700bfe5eed4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/12: Persuade->google/bigbird-roberta-base->bio at PATH: drive/MyDrive/Desktop/tmpdir/job/820965.undefined/models/Z29vZ2xlL2JpZ2JpcmQtcm9iZXJ0YS1iYXNlX2ZpbmFs\n",
            "=================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: UserWarning: LOADING LIMITED DATA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded and data loaded. Time:  6.22\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-aa547dbc6ae0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mSELF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'self'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mdf_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mmacro_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_scores_agg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_scores_agg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mRESULTS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSELF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'core'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'avgs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmacro_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'scores'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdf_scores_agg\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/argminer/evaluation.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(model, testloader, metrics)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;31m# set model to test mode, set correct device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;31m# get mapping to move from positional labels to core labels, e.g. 'B-{type}' becomes '{type}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    897\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m     def register_backward_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    895\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    896\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 897\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
          ]
        }
      ],
      "source": [
        "for MODEL_ID, job in enumerate(os.listdir(JOB_DIR)):\n",
        "    limit = 500\n",
        "    if job != '.DS_Store':\n",
        "        job_path = os.path.join(JOB_DIR, job)\n",
        "        model_dir = os.path.join(job_path, 'models')\n",
        "        model_name = [item for item in os.listdir(model_dir) if item != '.DS_Store'][0]\n",
        "        model_name_decoded = decode_model_name(model_name).split('_')[0] # get base model name\n",
        "        \n",
        "        max_length = MAX_LENGTH_DICT[model_name_decoded]\n",
        "        # define tokenizer\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name_decoded, add_prefix_space=True)\n",
        "        model_path = os.path.join(model_dir, model_name)\n",
        "        \n",
        "        strategy = CONFIG_MAP[job].get('strat')\n",
        "        Processor = CONFIG_MAP[job].get('processor')\n",
        "        dataset = CONFIG_MAP[job].get('dataset')\n",
        "        if dataset == 'TUDarmstadt':\n",
        "          continue\n",
        "        print(\n",
        "            f'{MODEL_ID+1}/12: {dataset}->{model_name_decoded}->{strategy} at PATH: {model_path}'\n",
        "        )\n",
        "        print('=================================================================================')\n",
        "        \n",
        "        \n",
        "\n",
        "\n",
        "        s = time.time()\n",
        "        trained_model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
        "        \n",
        "        RESULTS[job] = {}\n",
        "        \n",
        "        # test the model against itself\n",
        "        RESULTS[job]['self'] = {}\n",
        "        \n",
        "        # specify the path to the json\n",
        "        path = os.path.join(MODEL_PATH, strategy)\n",
        "        testloader = _get_core_data(path, Processor, strategy, batch_size=BATCH_SIZE, limit=limit)\n",
        "        print(f'Loaded and data loaded. Time: {time.time() - s: .3g}')\n",
        "\n",
        "\n",
        "        # TODO add metrics support\n",
        "        SELF = 'self'\n",
        "        s = time.time()\n",
        "        df_metrics, df_scores = inference(trained_model, testloader, )\n",
        "        macro_f1, df_scores_agg = _get_scores_agg(df_scores)\n",
        "        RESULTS[job][SELF]['core'] = {'avgs': macro_f1, 'scores': df_scores_agg}\n",
        "        \n",
        "        print(f'Took {time.time() -s:.3g} to get scores')\n",
        "        \n",
        "        \n",
        "        \n",
        "        # test models against self adversarial examples\n",
        "        augmented_path = os.path.join(TEST_DIR, strategy)\n",
        "        for augmentation in os.listdir(augmented_path):\n",
        "            if augmentation != '.DS_Store':\n",
        "                print(f'RUNNING AUGMENTATION: {augmentation}')\n",
        "                augmentation_path = os.path.join(augmented_path, augmentation)\n",
        "                testloader = _get_core_data(augmentation_path, Processor, strategy,\n",
        "                                                       batch_size=BATCH_SIZE, limit=limit)\n",
        "                df_metrics, df_scores = inference(trained_model, testloader, )\n",
        "                macro_f1, df_scores_agg = _get_scores_agg(df_scores)\n",
        "                RESULTS[job][SELF][augmentation] = {'avgs': macro_f1, 'scores': df_scores_agg}\n",
        "                # aggregate the scores\n",
        "        \n",
        "        \n",
        "        '''OTHER = 'other'\n",
        "        RESULTS[job][OTHER] = {}\n",
        "        \n",
        "        # get other processor\n",
        "        testloader = _get_other_data(path, Processor, strategy, batch_size=BATCH_SIZE, limit=LIMIT)\n",
        "        df_metrics, df_scores = inference(trained_model, testloader)\n",
        "        macro_f1, df_scores_agg = _get_scores_agg(df_scores)\n",
        "        RESULTS[job][OTHER]['core'] = {'macro_f1': macro_f1, 'scores': df_scores_agg}\n",
        "        \n",
        "        \n",
        "        for augmentation in os.listdir(augmented_path):\n",
        "            if augmentation != '.DS_Store':\n",
        "                augmentation_path = os.path.join(augmented_path, augmentation)\n",
        "                testloader = _get_other_data(augmentation_path, Processor, strategy,\n",
        "                                             batch_size=BATCH_SIZE, limit=LIMIT)\n",
        "                df_metrics, df_scores = inference(trained_model, testloader)\n",
        "                macro_f1, df_scores_agg = _get_scores_agg(df_scores)\n",
        "                RESULTS[job][OTHER][augmentation] = {'macro_f1': macro_f1, 'scores': df_scores_agg}'''\n",
        "        \n",
        "        #RESULTS[model_name_decoded]['self']['core'] # the score\n",
        "        \n",
        "        \n",
        "        # test model against other datasets, need to convert datasets\n",
        "        #RESULTS[model_name_decoded]['transfer'] = {}\n",
        "\n",
        "\n",
        "        \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ohQZS0RZxuhL"
      },
      "id": "ohQZS0RZxuhL",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "argument-mining",
      "language": "python",
      "name": "argument-mining"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "name": "Final_Inference.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}