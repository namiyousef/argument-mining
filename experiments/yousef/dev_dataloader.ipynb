{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9d2c16f",
   "metadata": {},
   "source": [
    "# Development Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51853cce",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57ddaf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- public imports\n",
    "\n",
    "from transformers import BigBirdTokenizer, AutoTokenizer, AutoModelForTokenClassification, AutoConfig\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe460c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import of ArgMiner successful\n"
     ]
    }
   ],
   "source": [
    "# -- private import\n",
    "from argminer.data import KaggleDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20077bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Drive import failed... continuing anyways...\n",
      "CUDA device NOT detected. Using CPU...\n"
     ]
    }
   ],
   "source": [
    "# -- dev imports\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from python_files.data import create_labels_doc_level\n",
    "from python_files.run import train_longformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a80de8",
   "metadata": {},
   "source": [
    "## Model Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e459e0d",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e00fe9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n",
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BigBirdTokenizer.from_pretrained('google/bigbird-roberta-large')\n",
    "tokenizer = AutoTokenizer.from_pretrained('google/bigbird-roberta-large', add_prefix_space=True)\n",
    "# def need an encoding function to categoize the inputs or at least to release them, maybe need to store them together tbh?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd05899",
   "metadata": {},
   "source": [
    "### Model and Optmizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c5fc460",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bigbird-roberta-large were not used when initializing BigBirdForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BigBirdForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BigBirdForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BigBirdForTokenClassification were not initialized from the model checkpoint at google/bigbird-roberta-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config_model = AutoConfig.from_pretrained('google/bigbird-roberta-large') \n",
    "config_model.num_labels = 3 # might have to change if we're using the numbered discourse type as well\n",
    "#config_model.save_pretrained('model')\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained('google/bigbird-roberta-large', config=config_model)\n",
    "optimizer = torch.optim.Adam(params=model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c4f0c3",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "990172d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "            'Hi my name is Yousef Nami',\n",
    "            'Hi I am Shirin'\n",
    "        ]\n",
    "labels = [\n",
    "    ['O', 'O', 'O', 'O', 'B-PERS', 'I-PERS'],\n",
    "    ['O', 'O', 'O', 'B-PERS']\n",
    "]\n",
    "\n",
    "# TODO see if bert can accept text inputs?\n",
    "labels_numeric = [\n",
    "    [0, 0, 0, 0, 1, 2],\n",
    "    [0, 0, 0, 1]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c3bb28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "        'text': texts,\n",
    "        'labels': labels_numeric\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ad91646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = KaggleDataset(\n",
    "    df,\n",
    "    tokenizer,\n",
    "    max_length=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6db005dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "for (inputs, targets) in dataset:\n",
    "    print(targets)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e583f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"You sef Na mi\" -> \"BNAME, BNAME, INAME, INAME\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c86ed8",
   "metadata": {},
   "source": [
    "## Data Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6564d266",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset, shuffle=True, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "230ea70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA device NOT detected. Using CPU...\n",
      "EPOCH 1 STARTED\n",
      "---------------\n",
      "tensor(1.1120, grad_fn=<NllLossBackward0>)\n",
      "tensor([[[-0.0224, -0.0946,  0.0991],\n",
      "         [-0.0681, -0.0895,  0.0942],\n",
      "         [ 0.0401, -0.0928, -0.0653],\n",
      "         [-0.0004,  0.0033,  0.2081],\n",
      "         [-0.1006, -0.1141,  0.1016],\n",
      "         [-0.0174, -0.0251,  0.1580],\n",
      "         [ 0.0569,  0.0183,  0.0796],\n",
      "         [ 0.0120, -0.0319,  0.0621],\n",
      "         [-0.0059, -0.1213,  0.1128],\n",
      "         [-0.1177, -0.0320,  0.0397],\n",
      "         [-0.1405, -0.0022,  0.0908],\n",
      "         [ 0.0113, -0.0479,  0.1648],\n",
      "         [ 0.0282, -0.1020,  0.0731],\n",
      "         [-0.0592, -0.0598, -0.0445],\n",
      "         [ 0.2501, -0.1613, -0.2957],\n",
      "         [-0.0495, -0.1887,  0.0911],\n",
      "         [ 0.0622, -0.1628,  0.0522],\n",
      "         [-0.0403,  0.0131,  0.1195],\n",
      "         [ 0.0737, -0.0593,  0.0306],\n",
      "         [-0.0229,  0.0390,  0.1207]],\n",
      "\n",
      "        [[-0.0111,  0.0077, -0.1385],\n",
      "         [ 0.1553, -0.1344, -0.0256],\n",
      "         [ 0.1078,  0.0514,  0.1017],\n",
      "         [-0.0476, -0.0415, -0.0789],\n",
      "         [ 0.0973,  0.0938,  0.0463],\n",
      "         [ 0.0577, -0.1546, -0.1518],\n",
      "         [ 0.0545, -0.2481,  0.1881],\n",
      "         [-0.0679, -0.1901, -0.1746],\n",
      "         [ 0.1252, -0.1667, -0.1280],\n",
      "         [-0.0941, -0.1114,  0.0950],\n",
      "         [ 0.0820, -0.1333,  0.0462],\n",
      "         [ 0.0163,  0.0446,  0.1576],\n",
      "         [ 0.2016, -0.2051, -0.0514],\n",
      "         [ 0.1356, -0.1203,  0.0460],\n",
      "         [ 0.0216, -0.1291,  0.0221],\n",
      "         [-0.0955, -0.1579,  0.1346],\n",
      "         [ 0.0911, -0.2003, -0.1457],\n",
      "         [ 0.0908, -0.0258, -0.0203],\n",
      "         [ 0.1216, -0.0145,  0.0658],\n",
      "         [-0.0253, -0.0098,  0.0496]]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [86]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_longformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Main/0.Education/2.UCL/Courses/NLP/argument-mining/experiments/yousef/python_files/run.py:50\u001b[0m, in \u001b[0;36mtrain_longformer\u001b[0;34m(model, optimizer, loss, epochs, train_loader, val_loader)\u001b[0m\n\u001b[1;32m     48\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     49\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m()\n\u001b[1;32m     51\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss(outputs, targets)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m update_epoch_histories:\n",
      "\u001b[0;31mException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_longformer(model=model, optimizer=optimizer , epochs=1, train_loader=train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6df7d2e",
   "metadata": {},
   "source": [
    "## Test on Kaggle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0655a699",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../data/kaggle/feedback-prize-2021/train\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m FILE_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../data/kaggle/feedback-prize-2021/train.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m df_texts \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_labels_doc_level\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFILE_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#df_texts[['text', 'labels']].to_csv('../../../data/kaggle/df_cleaned.csv')\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#df_kaggle = pd.read_csv('../../data/kaggle/df_cleaned.csv')\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#df_kaggle.head()\u001b[39;00m\n\u001b[1;32m      9\u001b[0m df_texts\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/Desktop/Main/0.Education/2.UCL/Courses/NLP/argument-mining/experiments/yousef/python_files/data.py:83\u001b[0m, in \u001b[0;36mcreate_labels_doc_level\u001b[0;34m(path_to_text_dir, path_to_ground_truth)\u001b[0m\n\u001b[1;32m     79\u001b[0m     labels[ids] \u001b[38;5;241m=\u001b[39m new_labels\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(labels)\n\u001b[0;32m---> 83\u001b[0m df_texts\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m \u001b[43mdf_texts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_inplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m\"\"\"df_texts.text = df_texts.text.str.replace('\\n', ' ')\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03mdf_texts.text = df_texts.text.str.replace('\\s+', ' ')\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03mdf_texts.text = df_texts.text.str.replace('(?<=\\w) (?=[.,\\/#!$%\\^&\\*;:{}=\\-_`~()])', '')\"\"\"\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m#for i, (text, label) in df_texts[['text', 'labels']].iterrows():\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m#    assert text.split().__len__() == label.__len__(), f'Failed because of size mismatch on id: {i}. Shape mismatch {text.split().__len__(), label.__len__()}'\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/argument-mining/lib/python3.8/site-packages/pandas/core/frame.py:8833\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   8822\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m   8824\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m   8825\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   8826\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   8831\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m   8832\u001b[0m )\n\u001b[0;32m-> 8833\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/argument-mining/lib/python3.8/site-packages/pandas/core/apply.py:727\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[0;32m--> 727\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/argument-mining/lib/python3.8/site-packages/pandas/core/apply.py:851\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 851\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/argument-mining/lib/python3.8/site-packages/pandas/core/apply.py:867\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    865\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m    866\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    868\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    869\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    870\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    871\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/Main/0.Education/2.UCL/Courses/NLP/argument-mining/experiments/yousef/python_files/data.py:83\u001b[0m, in \u001b[0;36mcreate_labels_doc_level.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     79\u001b[0m     labels[ids] \u001b[38;5;241m=\u001b[39m new_labels\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(labels)\n\u001b[0;32m---> 83\u001b[0m df_texts\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m df_texts\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mupdate_inplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m\"\"\"df_texts.text = df_texts.text.str.replace('\\n', ' ')\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03mdf_texts.text = df_texts.text.str.replace('\\s+', ' ')\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03mdf_texts.text = df_texts.text.str.replace('(?<=\\w) (?=[.,\\/#!$%\\^&\\*;:{}=\\-_`~()])', '')\"\"\"\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m#for i, (text, label) in df_texts[['text', 'labels']].iterrows():\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m#    assert text.split().__len__() == label.__len__(), f'Failed because of size mismatch on id: {i}. Shape mismatch {text.split().__len__(), label.__len__()}'\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Main/0.Education/2.UCL/Courses/NLP/argument-mining/experiments/yousef/python_files/data.py:77\u001b[0m, in \u001b[0;36mcreate_labels_doc_level.<locals>.update_inplace\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     75\u001b[0m ids \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mrange\n\u001b[1;32m     76\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mlabels_temp\n\u001b[0;32m---> 77\u001b[0m labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabels\u001b[49m, dtype\u001b[38;5;241m=\u001b[39mnew_labels\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ids) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(new_labels)\n\u001b[1;32m     79\u001b[0m labels[ids] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/argument-mining/lib/python3.8/site-packages/pandas/core/generic.py:5582\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5574\u001b[0m \u001b[38;5;66;03m# Note: obj.x will always call obj.__getattribute__('x') prior to\u001b[39;00m\n\u001b[1;32m   5575\u001b[0m \u001b[38;5;66;03m# calling obj.__getattr__('x').\u001b[39;00m\n\u001b[1;32m   5576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5577\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   5578\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   5579\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   5580\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5581\u001b[0m ):\n\u001b[0;32m-> 5582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   5583\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/argument-mining/lib/python3.8/site-packages/pandas/core/series.py:958\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    955\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 958\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    963\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/argument-mining/lib/python3.8/site-packages/pandas/core/series.py:1069\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1069\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_values_for_loc(\u001b[38;5;28mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/argument-mining/lib/python3.8/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3619\u001b[0m casted_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_indexer(key)\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "PATH = '../../data/kaggle/feedback-prize-2021/train'\n",
    "FILE_PATH = '../../data/kaggle/feedback-prize-2021/train.csv'\n",
    "\n",
    "df_texts = create_labels_doc_level(PATH, FILE_PATH)\n",
    "#df_texts[['text', 'labels']].to_csv('../../../data/kaggle/df_cleaned.csv')\n",
    "\n",
    "#df_kaggle = pd.read_csv('../../data/kaggle/df_cleaned.csv')\n",
    "#df_kaggle.head()\n",
    "df_texts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38591aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I do agree that some students would benefit fr...</td>\n",
       "      <td>[1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Should students design a summer project for sc...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 4, 4, 4, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dear State Senator\\n\\n,\\n\\nIn the ruels of vot...</td>\n",
       "      <td>[0, 0, 0, 0, 3, 4, 4, 4, 4, 4, 4, 4, 4, 7, 8, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>People sometimes have a different opinion than...</td>\n",
       "      <td>[1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dear senator,\\n\\nAs you know the Electoral Col...</td>\n",
       "      <td>[0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  I do agree that some students would benefit fr...   \n",
       "1  Should students design a summer project for sc...   \n",
       "2  Dear State Senator\\n\\n,\\n\\nIn the ruels of vot...   \n",
       "3  People sometimes have a different opinion than...   \n",
       "4  Dear senator,\\n\\nAs you know the Electoral Col...   \n",
       "\n",
       "                                              labels  \n",
       "0  [1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 4, 4, 4, 4, ...  \n",
       "2  [0, 0, 0, 0, 3, 4, 4, 4, 4, 4, 4, 4, 4, 7, 8, ...  \n",
       "3  [1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  \n",
       "4  [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kaggle = df_texts[['text', 'labels']]\n",
    "df_kaggle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01b42959",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_dataset = KaggleDataset(df, tokenizer, max_length=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3429cf53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([   65, 16003,   717,  1539,   419,   676,   617,   992,   500,  6378,\n",
      "           66,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])}\n"
     ]
    }
   ],
   "source": [
    "for (inputs, targets) in kaggle_dataset:\n",
    "    print(inputs)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd5b1225",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_train_loader = DataLoader(kaggle_dataset, shuffle=True, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ccc40760",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attention type 'block_sparse' is not possible if sequence_length: 20 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 STARTED\n",
      "---------------\n",
      "tensor(1.0604, grad_fn=<NllLossBackward0>)\n",
      "tensor([[[-0.1543, -0.0606, -0.1969],\n",
      "         [-0.0912,  0.0348, -0.0372],\n",
      "         [ 0.0957,  0.2102,  0.1286],\n",
      "         [ 0.4059,  0.4303,  0.0561],\n",
      "         [ 0.8208,  0.8731, -0.2832],\n",
      "         [ 0.0943,  0.1394, -0.4872],\n",
      "         [ 0.2177,  0.0998, -0.0414],\n",
      "         [ 0.2388,  0.5826, -0.4362],\n",
      "         [ 0.2919,  0.1661,  0.0572],\n",
      "         [-0.2495,  0.1740, -0.3572],\n",
      "         [ 0.3496,  0.3546,  0.2610],\n",
      "         [ 0.2826,  0.4353, -0.3105],\n",
      "         [-0.1331, -0.0448, -0.2625],\n",
      "         [ 0.3561,  0.1659, -0.1571],\n",
      "         [-0.1036, -0.0262, -0.2957],\n",
      "         [ 0.0132,  0.1542, -0.4864],\n",
      "         [ 0.2793,  0.2334, -0.1412],\n",
      "         [-0.1528, -0.0184, -0.2182],\n",
      "         [-0.1823, -0.0512, -0.2283],\n",
      "         [-0.1329, -0.0350, -0.2510]]], grad_fn=<AddBackward0>) torch.Size([1, 20, 3])\n",
      "Batch 1 complete. Time taken: load(0.0131), train(18.6), total(18.6). \n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_longformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk_train_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Main/0.Education/2.UCL/Courses/NLP/argument-mining/experiments/yousef/python_files/run.py:59\u001b[0m, in \u001b[0;36mtrain_longformer\u001b[0;34m(model, optimizer, epochs, train_loader, val_loader, verbose)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBatch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m complete. Time taken: load(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_train \u001b[38;5;241m-\u001b[39m start_load\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3g\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m), \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_train \u001b[38;5;241m-\u001b[39m start_train\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3g\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m), total(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_train \u001b[38;5;241m-\u001b[39m start_load\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3g\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     57\u001b[0m     )\n\u001b[1;32m     58\u001b[0m start_load \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m()\n",
      "\u001b[0;31mException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_longformer(model=model, optimizer=optimizer, epochs=1, train_loader=k_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c3636ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_logits(raw_logits, word_ids):\n",
    "    word_ids = word_ids.view(-1)\n",
    "    active_mask = word_ids.unsqueeze(1).expand(word_ids.shape[0], 3)\n",
    "    print(active_mask)\n",
    "    active_mask = active_mask != -1\n",
    "    active_logits = raw_logits.view(-1, 3)\n",
    "    print(active_logits)\n",
    "    active_logits = torch.masked_select(active_logits, active_mask) # return 1dTensor\n",
    "    active_logits = active_logits.view(-1, 3) \n",
    "    return active_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3f3a068f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1, -1, -1],\n",
      "        [ 0,  0,  0],\n",
      "        [ 1,  1,  1],\n",
      "        [ 2,  2,  2],\n",
      "        [ 3,  3,  3],\n",
      "        [ 4,  4,  4],\n",
      "        [ 4,  4,  4],\n",
      "        [ 5,  5,  5],\n",
      "        [ 5,  5,  5],\n",
      "        [ 5,  5,  5],\n",
      "        [-1, -1, -1]])\n",
      "tensor([[0.9573, 0.3607, 0.6314],\n",
      "        [0.4865, 0.2565, 0.6984],\n",
      "        [0.4938, 0.6211, 0.6231],\n",
      "        [0.1811, 0.8638, 0.6316],\n",
      "        [0.6443, 0.3207, 0.4406],\n",
      "        [0.1913, 0.6350, 0.8052],\n",
      "        [0.2440, 0.1049, 0.7696],\n",
      "        [0.5300, 0.6490, 0.8611],\n",
      "        [0.2157, 0.6968, 0.4399],\n",
      "        [0.8934, 0.0529, 0.4582],\n",
      "        [0.0897, 0.0093, 0.6105]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.4865, 0.2565, 0.6984],\n",
       "        [0.4938, 0.6211, 0.6231],\n",
       "        [0.1811, 0.8638, 0.6316],\n",
       "        [0.6443, 0.3207, 0.4406],\n",
       "        [0.1913, 0.6350, 0.8052],\n",
       "        [0.2440, 0.1049, 0.7696],\n",
       "        [0.5300, 0.6490, 0.8611],\n",
       "        [0.2157, 0.6968, 0.4399],\n",
       "        [0.8934, 0.0529, 0.4582]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_ids = tokenizer('Hi my name is سیس Yousef').word_ids()\n",
    "L = len(word_ids)\n",
    "word_ids = [word_id if word_id is not None else -1 for word_id in word_ids]\n",
    "word_ids = torch.tensor(word_ids)\n",
    "\n",
    "raw_logits = torch.rand((L, 3))\n",
    "active_logits(raw_logits, word_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bb497c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "# need help with this\n",
    "IGNORE_INDEX = -100\n",
    "NON_LABEL = -1\n",
    "LABELS_TO_IDS = {\n",
    "    'O': 0,\n",
    "    'B-PERS': 1,\n",
    "    'I-PERS': 2\n",
    "}\n",
    "\n",
    "df = pd.DataFrame({\n",
    "        'text': texts,\n",
    "        'entities': labels\n",
    "    })\n",
    "\n",
    "SUBTOKENS = True\n",
    "class FeedbackPrizeDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len, has_labels):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.has_labels = has_labels\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = self.data.text[index]\n",
    "        encoding = self.tokenizer(\n",
    "            text.split(),\n",
    "            is_split_into_words = True,\n",
    "            padding = 'max_length',\n",
    "            truncation = True,\n",
    "            max_length = self.max_len\n",
    "        )\n",
    "        word_ids = encoding.word_ids()\n",
    "\n",
    "        # targets\n",
    "        if self.has_labels:\n",
    "            word_labels = self.data.entities[index]\n",
    "            prev_word_idx = None\n",
    "            labels_ids = []\n",
    "            for word_idx in word_ids:\n",
    "                if word_idx is None:\n",
    "                    labels_ids.append(IGNORE_INDEX)\n",
    "                elif word_idx != prev_word_idx:\n",
    "                    labels_ids.append(LABELS_TO_IDS[word_labels[word_idx]])\n",
    "                else:\n",
    "                    if SUBTOKENS:\n",
    "                        labels_ids.append(LABELS_TO_IDS[word_labels[word_idx]])\n",
    "                    else:\n",
    "                        labels_ids.append(IGNORE_INDEX)\n",
    "                prev_word_idx = word_idx\n",
    "            encoding['labels'] = labels_ids\n",
    "        # convert to torch.tensor\n",
    "        item = {k: torch.as_tensor(v) for k, v in encoding.items()}\n",
    "        word_ids2 = [w if w is not None else NON_LABEL for w in word_ids]\n",
    "        item['word_ids'] = torch.as_tensor(word_ids2)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "dset = FeedbackPrizeDataset(df.rename(columns={'labels':'entities'}),  tokenizer,  10,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2c719715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_labels(labels):\n",
    "    active_mask = labels.view(-1) != IGNORE_INDEX\n",
    "    active_labels = torch.masked_select(labels.view(-1), active_mask)\n",
    "    return active_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "be755b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-100,    0,    0,    0,    0,    1,    1,    1,    2, -100])\n",
      "tensor([0, 0, 0, 0, 1, 1, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "for item in dset:\n",
    "    input_ids, attention_mask, labels, word_ids = item.values()\n",
    "    print(labels)\n",
    "    print(active_labels(labels))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f2b8fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "argument-mining",
   "language": "python",
   "name": "argument-mining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
