{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9d2c16f",
   "metadata": {},
   "source": [
    "# Development Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51853cce",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57ddaf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- public imports\n",
    "\n",
    "from transformers import BigBirdTokenizer, AutoTokenizer, AutoModelForTokenClassification, AutoConfig\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe460c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import of ArgMiner successful\n"
     ]
    }
   ],
   "source": [
    "# -- private import\n",
    "from argminer.data import KaggleDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20077bcd",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (data.py, line 115)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m~/opt/anaconda3/envs/argument-mining/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3251\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  Input \u001b[0;32mIn [3]\u001b[0;36m in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from python_files.data import create_labels_doc_level #, KaggleDataset\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m~/Desktop/Main/0.Education/2.UCL/Courses/NLP/argument-mining/experiments/yousef/python_files/data.py:115\u001b[0;36m\u001b[0m\n\u001b[0;31m    pass\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# -- dev imports\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from python_files.data import create_labels_doc_level #, KaggleDataset\n",
    "from python_files.run import train_longformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a80de8",
   "metadata": {},
   "source": [
    "## Model Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e459e0d",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e00fe9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n",
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    }
   ],
   "source": [
    "model = 'google/bigbird-roberta-large'\n",
    "\n",
    "tokenizer = BigBirdTokenizer.from_pretrained(model)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model, add_prefix_space=True)\n",
    "# def need an encoding function to categoize the inputs or at least to release them, maybe need to store them together tbh?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9061003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 0, 1, None]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('humans humans').word_ids()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd05899",
   "metadata": {},
   "source": [
    "### Model and Optmizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c5fc460",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bigbird-roberta-large were not used when initializing BigBirdForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BigBirdForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BigBirdForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BigBirdForTokenClassification were not initialized from the model checkpoint at google/bigbird-roberta-large and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config_model = AutoConfig.from_pretrained(model) \n",
    "config_model.num_labels = 3 # might have to change if we're using the numbered discourse type as well\n",
    "#config_model.save_pretrained('model')\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(model, config=config_model)\n",
    "optimizer = torch.optim.Adam(params=model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c4f0c3",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "990172d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "            'Hi my name is Yousef Nami',\n",
    "            'Hi I am Shirin'\n",
    "        ]\n",
    "labels = [\n",
    "    ['O', 'O', 'O', 'O', 'B-PERS', 'I-PERS'],\n",
    "    ['O', 'O', 'O', 'B-PERS']\n",
    "]\n",
    "\n",
    "# TODO see if bert can accept text inputs?\n",
    "labels_numeric = [\n",
    "    [0, 0, 0, 0, 1, 2],\n",
    "    [0, 0, 0, 1]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9c3bb28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "        'text': texts,\n",
    "        'labels': labels_numeric\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ad91646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = KaggleDataset(\n",
    "    df,\n",
    "    tokenizer,\n",
    "    max_length=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "6db005dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([   65, 16003,   717,  1539,   419,   676,   617,   992,   500,  6378,\n",
      "           66,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'doc_ids': 0, 'word_ids': [0, 1, 2, 3, 4, 4, 4, 5, 5]}\n",
      "{'input_ids': tensor([   65, 16003,   415,   817,  1012, 47489,    66,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'doc_ids': 1, 'word_ids': [0, 1, 2, 3, 3]}\n"
     ]
    }
   ],
   "source": [
    "for (inputs, targets) in dataset:\n",
    "    print(inputs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e583f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"You sef Na mi\" -> \"BNAME, BNAME, INAME, INAME\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c86ed8",
   "metadata": {},
   "source": [
    "## Data Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6564d266",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(\u001b[43mdataset\u001b[49m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(dataset, shuffle=True, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230ea70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_longformer(model=model, optimizer=optimizer , epochs=1, train_loader=train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6df7d2e",
   "metadata": {},
   "source": [
    "## Test on Kaggle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0655a699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_split</th>\n",
       "      <th>labels</th>\n",
       "      <th>range</th>\n",
       "      <th>labels_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3321A3E87AD3</td>\n",
       "      <td>I do agree that some students would benefit fr...</td>\n",
       "      <td>[I, do, agree, that, some, students, would, be...</td>\n",
       "      <td>[1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DFEAEC512BAB</td>\n",
       "      <td>Should students design a summer project for sc...</td>\n",
       "      <td>[Should, students, design, a, summer, project,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 4, 4, 4, 4, ...</td>\n",
       "      <td>[8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...</td>\n",
       "      <td>[3, 4, 4, 4, 4, 4, 4, 7, 8, 8, 8, 8, 8, 8, 8, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2E4AFCD3987F</td>\n",
       "      <td>Dear State Senator\\n\\n,\\n\\nIn the ruels of vot...</td>\n",
       "      <td>[Dear, State, Senator, ,, In, the, ruels, of, ...</td>\n",
       "      <td>[0, 0, 0, 0, 3, 4, 4, 4, 4, 4, 4, 4, 4, 7, 8, ...</td>\n",
       "      <td>[4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,...</td>\n",
       "      <td>[3, 4, 4, 4, 4, 4, 4, 4, 4, 7, 8, 8, 8, 8, 8, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EB6C2AF20BFE</td>\n",
       "      <td>People sometimes have a different opinion than...</td>\n",
       "      <td>[People, sometimes, have, a, different, opinio...</td>\n",
       "      <td>[1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A91A08E523D5</td>\n",
       "      <td>Dear senator,\\n\\nAs you know the Electoral Col...</td>\n",
       "      <td>[Dear, senator,, As, you, know, the, Electoral...</td>\n",
       "      <td>[0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...</td>\n",
       "      <td>[1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text  \\\n",
       "0  3321A3E87AD3  I do agree that some students would benefit fr...   \n",
       "1  DFEAEC512BAB  Should students design a summer project for sc...   \n",
       "2  2E4AFCD3987F  Dear State Senator\\n\\n,\\n\\nIn the ruels of vot...   \n",
       "3  EB6C2AF20BFE  People sometimes have a different opinion than...   \n",
       "4  A91A08E523D5  Dear senator,\\n\\nAs you know the Electoral Col...   \n",
       "\n",
       "                                          text_split  \\\n",
       "0  [I, do, agree, that, some, students, would, be...   \n",
       "1  [Should, students, design, a, summer, project,...   \n",
       "2  [Dear, State, Senator, ,, In, the, ruels, of, ...   \n",
       "3  [People, sometimes, have, a, different, opinio...   \n",
       "4  [Dear, senator,, As, you, know, the, Electoral...   \n",
       "\n",
       "                                              labels  \\\n",
       "0  [1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 4, 4, 4, 4, ...   \n",
       "2  [0, 0, 0, 0, 3, 4, 4, 4, 4, 4, 4, 4, 4, 7, 8, ...   \n",
       "3  [1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "4  [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "\n",
       "                                               range  \\\n",
       "0  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "1  [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...   \n",
       "2  [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,...   \n",
       "3  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "4  [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...   \n",
       "\n",
       "                                         labels_temp  \n",
       "0  [1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  \n",
       "1  [3, 4, 4, 4, 4, 4, 4, 7, 8, 8, 8, 8, 8, 8, 8, ...  \n",
       "2  [3, 4, 4, 4, 4, 4, 4, 4, 4, 7, 8, 8, 8, 8, 8, ...  \n",
       "3  [1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  \n",
       "4  [1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '../../data/kaggle/feedback-prize-2021/train'\n",
    "FILE_PATH = '../../data/kaggle/feedback-prize-2021/train.csv'\n",
    "\n",
    "df_texts = create_labels_doc_level(PATH, FILE_PATH)\n",
    "#df_texts[['text', 'labels']].to_csv('../../../data/kaggle/df_cleaned.csv')\n",
    "\n",
    "#df_kaggle = pd.read_csv('../../data/kaggle/df_cleaned.csv')\n",
    "#df_kaggle.head()\n",
    "df_texts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38591aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I do agree that some students would benefit fr...</td>\n",
       "      <td>[1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Should students design a summer project for sc...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 4, 4, 4, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dear State Senator\\n\\n,\\n\\nIn the ruels of vot...</td>\n",
       "      <td>[0, 0, 0, 0, 3, 4, 4, 4, 4, 4, 4, 4, 4, 7, 8, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>People sometimes have a different opinion than...</td>\n",
       "      <td>[1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dear senator,\\n\\nAs you know the Electoral Col...</td>\n",
       "      <td>[0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  I do agree that some students would benefit fr...   \n",
       "1  Should students design a summer project for sc...   \n",
       "2  Dear State Senator\\n\\n,\\n\\nIn the ruels of vot...   \n",
       "3  People sometimes have a different opinion than...   \n",
       "4  Dear senator,\\n\\nAs you know the Electoral Col...   \n",
       "\n",
       "                                              labels  \n",
       "0  [1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 4, 4, 4, 4, ...  \n",
       "2  [0, 0, 0, 0, 3, 4, 4, 4, 4, 4, 4, 4, 4, 7, 8, ...  \n",
       "3  [1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  \n",
       "4  [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kaggle = df_texts[['text', 'labels']]\n",
    "df_kaggle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "01b42959",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test =pd.DataFrame(data={'text':['hi my name is Yousef'], 'labels': [1]})\n",
    "\n",
    "kaggle_dataset = KaggleDataset(df_test, tokenizer, max_length=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3429cf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (inputs, targets) in kaggle_dataset:\n",
    "    print(inputs)\n",
    "    print(targets)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "fd5b1225",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [153]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m k_train_loader \u001b[38;5;241m=\u001b[39m DataLoader(kaggle_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (inputs, targets) \u001b[38;5;129;01min\u001b[39;00m k_train_loader:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(inputs)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/argument-mining/lib/python3.8/site-packages/torch/utils/data/dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 521\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/argument-mining/lib/python3.8/site-packages/torch/utils/data/dataloader.py:561\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    560\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 561\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    563\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/argument-mining/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/argument-mining/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Desktop/Main/0.Education/2.UCL/Courses/NLP/argument-mining/experiments/yousef/python_files/data.py:58\u001b[0m, in \u001b[0;36mKaggleDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     56\u001b[0m targets \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(targets, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m     57\u001b[0m expanded_targets \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_length, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[0;32m---> 58\u001b[0m expanded_targets[word_id_mask] \u001b[38;5;241m=\u001b[39m \u001b[43mtargets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mword_ids\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (inputs, expanded_targets)\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 0"
     ]
    }
   ],
   "source": [
    "k_train_loader = DataLoader(kaggle_dataset, batch_size=2)\n",
    "for (inputs, targets) in k_train_loader:\n",
    "    print(inputs)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ccc40760",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attention type 'block_sparse' is not possible if sequence_length: 20 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 STARTED\n",
      "---------------\n",
      "tensor(1.0604, grad_fn=<NllLossBackward0>)\n",
      "tensor([[[-0.1543, -0.0606, -0.1969],\n",
      "         [-0.0912,  0.0348, -0.0372],\n",
      "         [ 0.0957,  0.2102,  0.1286],\n",
      "         [ 0.4059,  0.4303,  0.0561],\n",
      "         [ 0.8208,  0.8731, -0.2832],\n",
      "         [ 0.0943,  0.1394, -0.4872],\n",
      "         [ 0.2177,  0.0998, -0.0414],\n",
      "         [ 0.2388,  0.5826, -0.4362],\n",
      "         [ 0.2919,  0.1661,  0.0572],\n",
      "         [-0.2495,  0.1740, -0.3572],\n",
      "         [ 0.3496,  0.3546,  0.2610],\n",
      "         [ 0.2826,  0.4353, -0.3105],\n",
      "         [-0.1331, -0.0448, -0.2625],\n",
      "         [ 0.3561,  0.1659, -0.1571],\n",
      "         [-0.1036, -0.0262, -0.2957],\n",
      "         [ 0.0132,  0.1542, -0.4864],\n",
      "         [ 0.2793,  0.2334, -0.1412],\n",
      "         [-0.1528, -0.0184, -0.2182],\n",
      "         [-0.1823, -0.0512, -0.2283],\n",
      "         [-0.1329, -0.0350, -0.2510]]], grad_fn=<AddBackward0>) torch.Size([1, 20, 3])\n",
      "Batch 1 complete. Time taken: load(0.0131), train(18.6), total(18.6). \n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_longformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk_train_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Main/0.Education/2.UCL/Courses/NLP/argument-mining/experiments/yousef/python_files/run.py:59\u001b[0m, in \u001b[0;36mtrain_longformer\u001b[0;34m(model, optimizer, epochs, train_loader, val_loader, verbose)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBatch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m complete. Time taken: load(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_train \u001b[38;5;241m-\u001b[39m start_load\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3g\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m), \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_train \u001b[38;5;241m-\u001b[39m start_train\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3g\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m), total(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_train \u001b[38;5;241m-\u001b[39m start_load\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3g\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     57\u001b[0m     )\n\u001b[1;32m     58\u001b[0m start_load \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m()\n",
      "\u001b[0;31mException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_longformer(model=model, optimizer=optimizer, epochs=1, train_loader=k_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c3636ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_logits(raw_logits, word_ids):\n",
    "    word_ids = word_ids.view(-1)\n",
    "    active_mask = word_ids.unsqueeze(1).expand(word_ids.shape[0], 3)\n",
    "    print(active_mask)\n",
    "    active_mask = active_mask != -1\n",
    "    active_logits = raw_logits.view(-1, 3)\n",
    "    print(active_logits)\n",
    "    active_logits = torch.masked_select(active_logits, active_mask) # return 1dTensor\n",
    "    active_logits = active_logits.view(-1, 3) \n",
    "    return active_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3f3a068f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1, -1, -1],\n",
      "        [ 0,  0,  0],\n",
      "        [ 1,  1,  1],\n",
      "        [ 2,  2,  2],\n",
      "        [ 3,  3,  3],\n",
      "        [ 4,  4,  4],\n",
      "        [ 4,  4,  4],\n",
      "        [ 5,  5,  5],\n",
      "        [ 5,  5,  5],\n",
      "        [ 5,  5,  5],\n",
      "        [-1, -1, -1]])\n",
      "tensor([[0.9573, 0.3607, 0.6314],\n",
      "        [0.4865, 0.2565, 0.6984],\n",
      "        [0.4938, 0.6211, 0.6231],\n",
      "        [0.1811, 0.8638, 0.6316],\n",
      "        [0.6443, 0.3207, 0.4406],\n",
      "        [0.1913, 0.6350, 0.8052],\n",
      "        [0.2440, 0.1049, 0.7696],\n",
      "        [0.5300, 0.6490, 0.8611],\n",
      "        [0.2157, 0.6968, 0.4399],\n",
      "        [0.8934, 0.0529, 0.4582],\n",
      "        [0.0897, 0.0093, 0.6105]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.4865, 0.2565, 0.6984],\n",
       "        [0.4938, 0.6211, 0.6231],\n",
       "        [0.1811, 0.8638, 0.6316],\n",
       "        [0.6443, 0.3207, 0.4406],\n",
       "        [0.1913, 0.6350, 0.8052],\n",
       "        [0.2440, 0.1049, 0.7696],\n",
       "        [0.5300, 0.6490, 0.8611],\n",
       "        [0.2157, 0.6968, 0.4399],\n",
       "        [0.8934, 0.0529, 0.4582]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_ids = tokenizer('Hi my name is سیس Yousef').word_ids()\n",
    "L = len(word_ids)\n",
    "word_ids = [word_id if word_id is not None else -1 for word_id in word_ids]\n",
    "word_ids = torch.tensor(word_ids)\n",
    "\n",
    "raw_logits = torch.rand((L, 3))\n",
    "active_logits(raw_logits, word_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bb497c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "# need help with this\n",
    "IGNORE_INDEX = -100\n",
    "NON_LABEL = -1\n",
    "LABELS_TO_IDS = {\n",
    "    'O': 0,\n",
    "    'B-PERS': 1,\n",
    "    'I-PERS': 2\n",
    "}\n",
    "\n",
    "df = pd.DataFrame({\n",
    "        'text': texts,\n",
    "        'entities': labels\n",
    "    })\n",
    "\n",
    "SUBTOKENS = True\n",
    "class FeedbackPrizeDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len, has_labels):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.has_labels = has_labels\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = self.data.text[index]\n",
    "        encoding = self.tokenizer(\n",
    "            text.split(),\n",
    "            is_split_into_words = True,\n",
    "            padding = 'max_length',\n",
    "            truncation = True,\n",
    "            max_length = self.max_len\n",
    "        )\n",
    "        word_ids = encoding.word_ids()\n",
    "\n",
    "        # targets\n",
    "        if self.has_labels:\n",
    "            word_labels = self.data.entities[index]\n",
    "            prev_word_idx = None\n",
    "            labels_ids = []\n",
    "            for word_idx in word_ids:\n",
    "                if word_idx is None:\n",
    "                    labels_ids.append(IGNORE_INDEX)\n",
    "                elif word_idx != prev_word_idx:\n",
    "                    labels_ids.append(LABELS_TO_IDS[word_labels[word_idx]])\n",
    "                else:\n",
    "                    if SUBTOKENS:\n",
    "                        labels_ids.append(LABELS_TO_IDS[word_labels[word_idx]])\n",
    "                    else:\n",
    "                        labels_ids.append(IGNORE_INDEX)\n",
    "                prev_word_idx = word_idx\n",
    "            encoding['labels'] = labels_ids\n",
    "        # convert to torch.tensor\n",
    "        item = {k: torch.as_tensor(v) for k, v in encoding.items()}\n",
    "        word_ids2 = [w if w is not None else NON_LABEL for w in word_ids]\n",
    "        item['word_ids'] = torch.as_tensor(word_ids2)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "dset = FeedbackPrizeDataset(df.rename(columns={'labels':'entities'}),  tokenizer,  10,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2c719715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_labels(labels):\n",
    "    active_mask = labels.view(-1) != IGNORE_INDEX\n",
    "    active_labels = torch.masked_select(labels.view(-1), active_mask)\n",
    "    return active_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "be755b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-100,    0,    0,    0,    0,    1,    1,    1,    2, -100])\n",
      "tensor([0, 0, 0, 0, 1, 1, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "for item in dset:\n",
    "    input_ids, attention_mask, labels, word_ids = item.values()\n",
    "    print(labels)\n",
    "    print(active_labels(labels))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17e3aaf",
   "metadata": {},
   "source": [
    "# Model evalation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb25ed4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ True, False, False,  True],\n",
      "        [False, False, False,  True]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([2, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from python_files.run import evaluate\n",
    "\n",
    "t1 = torch.tensor([[1,2,3,4], [5,6,7,8]])\n",
    "t2 = torch.tensor([[1,3,2,4], [6, 7, 5, 8]])\n",
    "\n",
    "print(t1==t2)\n",
    "(t1 == t2).sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68afe6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t1 == 1).nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "75356eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(\n",
    "    {'t1': [set([1,2]), set([4,5])],\n",
    "    't2':[set([1,1]), set([4,5])]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "80c832b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['gt_and_pred'] = df_test.apply(lambda x: x.t1.intersection(x.t2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7118ad48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       {1}\n",
       "1    {4, 5}\n",
       "Name: gt_and_pred, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['gt_and_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a059c39e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 4, 6, 8],\n",
       "        [2, 2, 2, 4]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[1,2,3,4], [1,1,1,2]]).apply_(lambda x: x*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2efc6f41",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "torch.LongTensor is not a Module subclass",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [56]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModuleList\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/argument-mining/lib/python3.8/site-packages/torch/nn/modules/container.py:174\u001b[0m, in \u001b[0;36mModuleList.__init__\u001b[0;34m(self, modules)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28msuper\u001b[39m(ModuleList, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m modules \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m modules\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/argument-mining/lib/python3.8/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mModuleList.__iadd__\u001b[0;34m(self, modules)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iadd__\u001b[39m(\u001b[38;5;28mself\u001b[39m, modules: Iterable[Module]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModuleList\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodules\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/argument-mining/lib/python3.8/site-packages/torch/nn/modules/container.py:254\u001b[0m, in \u001b[0;36mModuleList.extend\u001b[0;34m(self, modules)\u001b[0m\n\u001b[1;32m    252\u001b[0m offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(modules):\n\u001b[0;32m--> 254\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/argument-mining/lib/python3.8/site-packages/torch/nn/modules/module.py:377\u001b[0m, in \u001b[0;36mModule.add_module\u001b[0;34m(self, name, module)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Adds a child module to the current module.\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03mThe module can be accessed as an attribute using the given name.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    module (Module): child module to be added to the module.\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(module, Module) \u001b[38;5;129;01mand\u001b[39;00m module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 377\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m is not a Module subclass\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    378\u001b[0m         torch\u001b[38;5;241m.\u001b[39mtypename(module)))\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name, torch\u001b[38;5;241m.\u001b[39m_six\u001b[38;5;241m.\u001b[39mstring_classes):\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule name should be a string. Got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    381\u001b[0m         torch\u001b[38;5;241m.\u001b[39mtypename(name)))\n",
      "\u001b[0;31mTypeError\u001b[0m: torch.LongTensor is not a Module subclass"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "48ffc8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3, 4, 5, 6]),)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor_split(torch.arange(7), [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "f6ad18ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_zero_start_ids(iterable, split_by=[0]):\n",
    "    \"\"\" TODO run unit tests on this \"\"\"\n",
    "\n",
    "    split_by = set(split_by)\n",
    "    add_item = float(iterable[0]) in split_by\n",
    "    zero_start_ids = []\n",
    "    for i, item in enumerate(iterable):\n",
    "        if (float(item) in split_by) ^ add_item:\n",
    "            add_item = not add_item\n",
    "            zero_start_ids.append(i)\n",
    "    return zero_start_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "dce14bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 5, 6, 8, 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of python_files.run failed: Traceback (most recent call last):\n",
      "  File \"/Users/yousefnami/opt/anaconda3/envs/argument-mining/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 257, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/yousefnami/opt/anaconda3/envs/argument-mining/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/Users/yousefnami/opt/anaconda3/envs/argument-mining/lib/python3.8/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 604, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 839, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 976, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 906, in source_to_code\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/Users/yousefnami/Desktop/Main/0.Education/2.UCL/Courses/NLP/argument-mining/experiments/yousef/python_files/run.py\", line 99\n",
      "    def get_predicted_label(outputs):\n",
      "    ^\n",
      "IndentationError: expected an indented block\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0]),\n",
       " tensor([1, 2, 3]),\n",
       " tensor([0]),\n",
       " tensor([3, 5]),\n",
       " tensor([0, 0, 0]),\n",
       " tensor([5, 6]))"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([0, 0, 1,2,3, 0, 3,5,0,0,0,5,6])\n",
    "split_ids = _get_zero_start_ids(tensor)\n",
    "print(split_ids)\n",
    "torch.tensor_split(tensor, split_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "5c239d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 1, 2]), tensor([3, 5, 0]), tensor([0, 0, 5, 6]))"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor_split(torch.tensor([0, 0, \n",
    "1,2,3,5,0,0,0,5,6]), [4, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5f0fb449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA device NOT detected. Using CPU...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [65, 16003, 717, 1539, 321, 100, 372, 676, 617, 992, 66], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('Hi my name \\nis Yousef')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9043611c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 3])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = (torch.rand((2,4,3)) * 10).int()\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "209fb10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "probas, values = test.max(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f5ed77c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA device NOT detected. Using CPU...\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat(\n",
    "    [pd.DataFrame(data={'id':i, 'probas':probas, 'values':values}) for i, (probas, values) in enumerate(zip(probas, values))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "83976796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>probas</th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  probas  values\n",
       "0   0       6       0\n",
       "1   0       5       1\n",
       "2   0       9       1\n",
       "3   0       6       0\n",
       "0   1       8       0\n",
       "1   1       7       1\n",
       "2   1       9       2\n",
       "3   1       9       1"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5e953688",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(\n",
    "    [pd.DataFrame(data={'probas':probas, 'values':values, 'word_ids':[0,1,1,2]}).groupby('word_ids').head(1) for i, (probas, values) in enumerate(zip(probas, values))]\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7b0bb388",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA device NOT detected. Using CPU...\n"
     ]
    }
   ],
   "source": [
    "df['ids'] = [0,0,0,1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "9d3d0925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probas</th>\n",
       "      <th>values</th>\n",
       "      <th>word_ids</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ids</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[6, 5, 6]</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[8, 7, 9]</td>\n",
       "      <td>[0, 1, 1]</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        probas     values   word_ids\n",
       "ids                                 \n",
       "0    [6, 5, 6]  [0, 1, 0]  [0, 1, 2]\n",
       "1    [8, 7, 9]  [0, 1, 1]  [0, 1, 2]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = df.groupby('ids').agg({col: lambda x: x.values.flatten().tolist() for col in df.columns}).drop('ids', axis=1)\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9015b0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "def encode_model_name(model_name, epoch):\n",
    "    model_name_b = model_name.encode('ascii')\n",
    "    encoded_model_name = base64.b64encode(model_name_b).decode('ascii')\n",
    "    return encoded_model_name + f'_{epoch}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "937bafb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Z29vZ2xlL2JpZ2JpcmQ=_1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_model_name('google/bigbird', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1598cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "argument-mining",
   "language": "python",
   "name": "argument-mining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
