{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9d2c16f",
   "metadata": {},
   "source": [
    "# Development Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51853cce",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57ddaf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- public imports\n",
    "\n",
    "from transformers import BigBirdTokenizer, AutoTokenizer, AutoModelForTokenClassification, AutoConfig\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe460c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- private imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "20077bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# -- dev imports\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from python_files.data import KaggleDataset, create_labels_doc_level\n",
    "from python_files.run import train_longformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a80de8",
   "metadata": {},
   "source": [
    "## Model Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e459e0d",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e00fe9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n",
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BigBirdTokenizer.from_pretrained('google/bigbird-roberta-large')\n",
    "tokenizer = AutoTokenizer.from_pretrained('google/bigbird-roberta-large', add_prefix_space=True)\n",
    "# def need an encoding function to categoize the inputs or at least to release them, maybe need to store them together tbh?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd05899",
   "metadata": {},
   "source": [
    "### Model and Optmizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5c5fc460",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bigbird-roberta-large were not used when initializing BigBirdForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BigBirdForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BigBirdForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BigBirdForTokenClassification were not initialized from the model checkpoint at google/bigbird-roberta-large and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config_model = AutoConfig.from_pretrained('google/bigbird-roberta-large') \n",
    "config_model.num_labels = 3 # might have to change if we're using the numbered discourse type as well\n",
    "#config_model.save_pretrained('model')\n",
    "\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained('google/bigbird-roberta-large', config=config_model)\n",
    "optimizer = torch.optim.Adam(params=model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c4f0c3",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "990172d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "            'Hi my name is Yousef Nami',\n",
    "            'Hi I am Shirin'\n",
    "        ]\n",
    "labels = [\n",
    "    ['O', 'O', 'O', 'O', 'B-PERS', 'I-PERS'],\n",
    "    ['O', 'O', 'O', 'B-PERS']\n",
    "]\n",
    "\n",
    "# TODO see if bert can accept text inputs?\n",
    "labels_numeric = [\n",
    "    [0, 0, 0, 0, 1, 2],\n",
    "    [0, 0, 0, 1]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9c3bb28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "        'text': texts,\n",
    "        'labels': labels_numeric\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ad91646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = KaggleDataset(\n",
    "    df,\n",
    "    tokenizer,\n",
    "    max_length=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6db005dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "for (inputs, targets) in dataset:\n",
    "    print(targets)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e583f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"You sef Na mi\" -> \"BNAME, BNAME, INAME, INAME\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c86ed8",
   "metadata": {},
   "source": [
    "## Data Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6564d266",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset, shuffle=True, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "230ea70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA device NOT detected. Using CPU...\n",
      "EPOCH 1 STARTED\n",
      "---------------\n",
      "tensor(1.1120, grad_fn=<NllLossBackward0>)\n",
      "tensor([[[-0.0224, -0.0946,  0.0991],\n",
      "         [-0.0681, -0.0895,  0.0942],\n",
      "         [ 0.0401, -0.0928, -0.0653],\n",
      "         [-0.0004,  0.0033,  0.2081],\n",
      "         [-0.1006, -0.1141,  0.1016],\n",
      "         [-0.0174, -0.0251,  0.1580],\n",
      "         [ 0.0569,  0.0183,  0.0796],\n",
      "         [ 0.0120, -0.0319,  0.0621],\n",
      "         [-0.0059, -0.1213,  0.1128],\n",
      "         [-0.1177, -0.0320,  0.0397],\n",
      "         [-0.1405, -0.0022,  0.0908],\n",
      "         [ 0.0113, -0.0479,  0.1648],\n",
      "         [ 0.0282, -0.1020,  0.0731],\n",
      "         [-0.0592, -0.0598, -0.0445],\n",
      "         [ 0.2501, -0.1613, -0.2957],\n",
      "         [-0.0495, -0.1887,  0.0911],\n",
      "         [ 0.0622, -0.1628,  0.0522],\n",
      "         [-0.0403,  0.0131,  0.1195],\n",
      "         [ 0.0737, -0.0593,  0.0306],\n",
      "         [-0.0229,  0.0390,  0.1207]],\n",
      "\n",
      "        [[-0.0111,  0.0077, -0.1385],\n",
      "         [ 0.1553, -0.1344, -0.0256],\n",
      "         [ 0.1078,  0.0514,  0.1017],\n",
      "         [-0.0476, -0.0415, -0.0789],\n",
      "         [ 0.0973,  0.0938,  0.0463],\n",
      "         [ 0.0577, -0.1546, -0.1518],\n",
      "         [ 0.0545, -0.2481,  0.1881],\n",
      "         [-0.0679, -0.1901, -0.1746],\n",
      "         [ 0.1252, -0.1667, -0.1280],\n",
      "         [-0.0941, -0.1114,  0.0950],\n",
      "         [ 0.0820, -0.1333,  0.0462],\n",
      "         [ 0.0163,  0.0446,  0.1576],\n",
      "         [ 0.2016, -0.2051, -0.0514],\n",
      "         [ 0.1356, -0.1203,  0.0460],\n",
      "         [ 0.0216, -0.1291,  0.0221],\n",
      "         [-0.0955, -0.1579,  0.1346],\n",
      "         [ 0.0911, -0.2003, -0.1457],\n",
      "         [ 0.0908, -0.0258, -0.0203],\n",
      "         [ 0.1216, -0.0145,  0.0658],\n",
      "         [-0.0253, -0.0098,  0.0496]]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [86]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_longformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Main/0.Education/2.UCL/Courses/NLP/argument-mining/experiments/yousef/python_files/run.py:50\u001b[0m, in \u001b[0;36mtrain_longformer\u001b[0;34m(model, optimizer, loss, epochs, train_loader, val_loader)\u001b[0m\n\u001b[1;32m     48\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     49\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m()\n\u001b[1;32m     51\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss(outputs, targets)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m update_epoch_histories:\n",
      "\u001b[0;31mException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_longformer(model=model, optimizer=optimizer , epochs=1, train_loader=train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6df7d2e",
   "metadata": {},
   "source": [
    "## Test on Kaggle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0655a699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_split</th>\n",
       "      <th>labels</th>\n",
       "      <th>range</th>\n",
       "      <th>labels_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3321A3E87AD3</td>\n",
       "      <td>I do agree that some students would benefit fr...</td>\n",
       "      <td>[I, do, agree, that, some, students, would, be...</td>\n",
       "      <td>[1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DFEAEC512BAB</td>\n",
       "      <td>Should students design a summer project for sc...</td>\n",
       "      <td>[Should, students, design, a, summer, project,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 4, 4, 4, 4, ...</td>\n",
       "      <td>[8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...</td>\n",
       "      <td>[3, 4, 4, 4, 4, 4, 4, 7, 8, 8, 8, 8, 8, 8, 8, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2E4AFCD3987F</td>\n",
       "      <td>Dear State Senator\\n\\n,\\n\\nIn the ruels of vot...</td>\n",
       "      <td>[Dear, State, Senator, ,, In, the, ruels, of, ...</td>\n",
       "      <td>[0, 0, 0, 0, 3, 4, 4, 4, 4, 4, 4, 4, 4, 7, 8, ...</td>\n",
       "      <td>[4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,...</td>\n",
       "      <td>[3, 4, 4, 4, 4, 4, 4, 4, 4, 7, 8, 8, 8, 8, 8, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EB6C2AF20BFE</td>\n",
       "      <td>People sometimes have a different opinion than...</td>\n",
       "      <td>[People, sometimes, have, a, different, opinio...</td>\n",
       "      <td>[1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A91A08E523D5</td>\n",
       "      <td>Dear senator,\\n\\nAs you know the Electoral Col...</td>\n",
       "      <td>[Dear, senator,, As, you, know, the, Electoral...</td>\n",
       "      <td>[0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...</td>\n",
       "      <td>[1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text  \\\n",
       "0  3321A3E87AD3  I do agree that some students would benefit fr...   \n",
       "1  DFEAEC512BAB  Should students design a summer project for sc...   \n",
       "2  2E4AFCD3987F  Dear State Senator\\n\\n,\\n\\nIn the ruels of vot...   \n",
       "3  EB6C2AF20BFE  People sometimes have a different opinion than...   \n",
       "4  A91A08E523D5  Dear senator,\\n\\nAs you know the Electoral Col...   \n",
       "\n",
       "                                          text_split  \\\n",
       "0  [I, do, agree, that, some, students, would, be...   \n",
       "1  [Should, students, design, a, summer, project,...   \n",
       "2  [Dear, State, Senator, ,, In, the, ruels, of, ...   \n",
       "3  [People, sometimes, have, a, different, opinio...   \n",
       "4  [Dear, senator,, As, you, know, the, Electoral...   \n",
       "\n",
       "                                              labels  \\\n",
       "0  [1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 4, 4, 4, 4, ...   \n",
       "2  [0, 0, 0, 0, 3, 4, 4, 4, 4, 4, 4, 4, 4, 7, 8, ...   \n",
       "3  [1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "4  [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "\n",
       "                                               range  \\\n",
       "0  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "1  [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...   \n",
       "2  [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,...   \n",
       "3  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "4  [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...   \n",
       "\n",
       "                                         labels_temp  \n",
       "0  [1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  \n",
       "1  [3, 4, 4, 4, 4, 4, 4, 7, 8, 8, 8, 8, 8, 8, 8, ...  \n",
       "2  [3, 4, 4, 4, 4, 4, 4, 4, 4, 7, 8, 8, 8, 8, 8, ...  \n",
       "3  [1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  \n",
       "4  [1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '../../data/kaggle/feedback-prize-2021/train'\n",
    "FILE_PATH = '../../data/kaggle/feedback-prize-2021/train.csv'\n",
    "\n",
    "df_texts = create_labels_doc_level(PATH, FILE_PATH)\n",
    "#df_texts[['text', 'labels']].to_csv('../../../data/kaggle/df_cleaned.csv')\n",
    "\n",
    "#df_kaggle = pd.read_csv('../../data/kaggle/df_cleaned.csv')\n",
    "#df_kaggle.head()\n",
    "df_texts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "38591aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I do agree that some students would benefit fr...</td>\n",
       "      <td>[1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Should students design a summer project for sc...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 4, 4, 4, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dear State Senator\\n\\n,\\n\\nIn the ruels of vot...</td>\n",
       "      <td>[0, 0, 0, 0, 3, 4, 4, 4, 4, 4, 4, 4, 4, 7, 8, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>People sometimes have a different opinion than...</td>\n",
       "      <td>[1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dear senator,\\n\\nAs you know the Electoral Col...</td>\n",
       "      <td>[0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  I do agree that some students would benefit fr...   \n",
       "1  Should students design a summer project for sc...   \n",
       "2  Dear State Senator\\n\\n,\\n\\nIn the ruels of vot...   \n",
       "3  People sometimes have a different opinion than...   \n",
       "4  Dear senator,\\n\\nAs you know the Electoral Col...   \n",
       "\n",
       "                                              labels  \n",
       "0  [1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 4, 4, 4, 4, ...  \n",
       "2  [0, 0, 0, 0, 3, 4, 4, 4, 4, 4, 4, 4, 4, 7, 8, ...  \n",
       "3  [1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  \n",
       "4  [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kaggle = df_texts[['text', 'labels']]\n",
    "df_kaggle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "01b42959",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_dataset = KaggleDataset(df_kaggle, tokenizer, max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fd5b1225",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_train_loader = DataLoader(kaggle_dataset, shuffle=True, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc40760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 STARTED\n",
      "---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_longformer(model=model, optimizer=optimizer, epochs=1, train_loader=k_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3636ba1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "argument-mining",
   "language": "python",
   "name": "argument-mining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
