{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Potential Modifications:\n**other HuggingFace backbones  \nother heads designs  \nother architecture tricks like using hidden layer activations  \nother pre and post processing  \nquestion and answer instead of NER  \nother learning schedules, optimizers, etc  \nsliding window training  \nadjust attention of LongFormer  \nmore folds  \ndata augmentation  \nexternal data  **","metadata":{}},{"cell_type":"markdown","source":"### TURN OFF INTERNET\nIn code competitions, we must turn internet off to make a submission. This starter notebook shows how to download any transformer of your choice to a Kaggle dataset","metadata":{}},{"cell_type":"markdown","source":"# Import","metadata":{}},{"cell_type":"code","source":"import json\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport os\n\nfrom collections import defaultdict\nfrom torch.utils.data import Dataset, DataLoader\nimport pdb\nimport torch\nfrom torch import cuda\n\nfrom transformers import BigBirdTokenizer, AutoTokenizer, AutoModelForTokenClassification, AutoConfig\nimport pandas as pd\nfrom torch.utils.data import DataLoader\nimport torch\n","metadata":{"execution":{"iopub.status.busy":"2022-03-12T10:16:20.712825Z","iopub.execute_input":"2022-03-12T10:16:20.714274Z","iopub.status.idle":"2022-03-12T10:16:21.227208Z","shell.execute_reply.started":"2022-03-12T10:16:20.714195Z","shell.execute_reply":"2022-03-12T10:16:21.226212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Configuration","metadata":{}},{"cell_type":"code","source":"# import os\n# # DECLARE HOW MANY GPUS YOU WISH TO USE. \n# # KAGGLE ONLY HAS 1, BUT OFFLINE, YOU CAN USE MORE\n# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #0,1,2,3 for four gpu\n\n# # VERSION FOR SAVING MODEL WEIGHTS\n# VER=26\n\n# # IF VARIABLE IS NONE, THEN NOTEBOOK COMPUTES TOKENS\n# # OTHERWISE NOTEBOOK LOADS TOKENS FROM PATH\n# LOAD_TOKENS_FROM = '../input/py-bigbird-v26'\n\n# # IF VARIABLE IS NONE, THEN NOTEBOOK TRAINS A NEW MODEL\n# # OTHERWISE IT LOADS YOUR PREVIOUSLY TRAINED MODEL\n# LOAD_MODEL_FROM = '../input/py-bigbird-v26'\n\n# # IF FOLLOWING IS NONE, THEN NOTEBOOK \n# # USES INTERNET AND DOWNLOADS HUGGINGFACE \n# # CONFIG, TOKENIZER, AND MODEL\n# DOWNLOADED_MODEL_PATH = '../input/py-bigbird-v26' \n\n# if DOWNLOADED_MODEL_PATH is None:\n#     DOWNLOADED_MODEL_PATH = 'model'    \n# MODEL_NAME = 'google/bigbird-roberta-base'","metadata":{"execution":{"iopub.status.busy":"2022-03-12T10:26:25.232119Z","iopub.execute_input":"2022-03-12T10:26:25.23313Z","iopub.status.idle":"2022-03-12T10:26:25.240402Z","shell.execute_reply.started":"2022-03-12T10:26:25.233085Z","shell.execute_reply":"2022-03-12T10:26:25.238894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_checkpoints = \"allenai/longformer-base-4096\"","metadata":{"execution":{"iopub.status.busy":"2022-03-12T10:32:46.803964Z","iopub.execute_input":"2022-03-12T10:32:46.804444Z","iopub.status.idle":"2022-03-12T10:32:46.809504Z","shell.execute_reply.started":"2022-03-12T10:32:46.804408Z","shell.execute_reply":"2022-03-12T10:32:46.8087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/feedback-prize-2021/train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-03-12T09:48:21.692452Z","iopub.execute_input":"2022-03-12T09:48:21.69302Z","iopub.status.idle":"2022-03-12T09:48:23.407924Z","shell.execute_reply.started":"2022-03-12T09:48:21.692978Z","shell.execute_reply":"2022-03-12T09:48:23.406932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_names, train_texts = [], []\nfor f in list(os.listdir('../input/feedback-prize-2021/train')):\n    test_names.append(f.replace('.txt', ''))\n    train_texts.append(open('../input/feedback-prize-2021/train/' + f, 'r').read())\n    \ndoc_df = pd.DataFrame({'id': test_names, 'text': train_texts})\ndoc_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T09:48:23.409426Z","iopub.execute_input":"2022-03-12T09:48:23.409694Z","iopub.status.idle":"2022-03-12T09:49:15.833087Z","shell.execute_reply.started":"2022-03-12T09:48:23.409659Z","shell.execute_reply":"2022-03-12T09:49:15.831961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Dataset: Convert Train Text to NER Labels","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"entities = []\nfor index,row in doc_df.iterrows():\n    length_text = row['text'].split().__len__()\n    ent = [\"O\" for i in range(length_text)]\n\n    for idx,r in train_df[train_df['id'] == row['id']].iterrows():\n        \n        pred_idx = r['predictionstring'].split()\n        ent[int(pred_idx[0])] = f\"B-{r['discourse_type']}\"\n\n        for i in pred_idx[1:]:\n            ent[int(i)] = f\"I-{r['discourse_type']}\"\n        \n\n    entities.append(ent)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-12T09:49:15.835399Z","iopub.execute_input":"2022-03-12T09:49:15.83569Z","iopub.status.idle":"2022-03-12T09:56:25.118453Z","shell.execute_reply.started":"2022-03-12T09:49:15.835656Z","shell.execute_reply":"2022-03-12T09:56:25.117209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"doc_df['elements'] = entities\ndoc_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T09:56:25.120794Z","iopub.execute_input":"2022-03-12T09:56:25.121254Z","iopub.status.idle":"2022-03-12T09:56:25.157038Z","shell.execute_reply.started":"2022-03-12T09:56:25.121217Z","shell.execute_reply":"2022-03-12T09:56:25.155755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_labels = ['O', 'B-Lead', 'I-Lead', 'B-Position', 'I-Position', 'B-Claim', 'I-Claim', 'B-Counterclaim', 'I-Counterclaim', \n          'B-Rebuttal', 'I-Rebuttal', 'B-Evidence', 'I-Evidence', 'B-Concluding Statement', 'I-Concluding Statement']\n\nlabels_to_ids = {v:k for k,v in enumerate(output_labels)}\nids_to_labels = {k:v for k,v in enumerate(output_labels)}\n\ndoc_df['labels'] = doc_df['elements'].apply(lambda x: [labels_to_ids[i] for i in x])\n","metadata":{"execution":{"iopub.status.busy":"2022-03-12T09:56:25.158585Z","iopub.execute_input":"2022-03-12T09:56:25.158862Z","iopub.status.idle":"2022-03-12T09:56:26.163234Z","shell.execute_reply.started":"2022-03-12T09:56:25.15882Z","shell.execute_reply":"2022-03-12T09:56:26.162085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"doc_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T09:56:26.164947Z","iopub.execute_input":"2022-03-12T09:56:26.165319Z","iopub.status.idle":"2022-03-12T09:56:26.193993Z","shell.execute_reply.started":"2022-03-12T09:56:26.16527Z","shell.execute_reply":"2022-03-12T09:56:26.192939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check MAX LENGTH (we use 1024 wide tokens since the majority of text is less than 1024 tokens.)","metadata":{}},{"cell_type":"code","source":"### Check MAX LENGTH (we use 1024 wide tokens since the majority of text is less than 1024 tokens.)\n# def calc_len(text):\n#     ids = tokenizer(text)['input_ids']\n#     return len(ids)\n\n# tokenizer = BigBirdTokenizer.from_pretrained('google/bigbird-roberta-large')\n# doc_df['length'] = doc_df['text'].apply(calc_len)\n# do_df.describe()","metadata":{"execution":{"iopub.status.busy":"2022-03-08T00:03:16.796049Z","iopub.execute_input":"2022-03-08T00:03:16.796302Z","iopub.status.idle":"2022-03-08T00:03:19.449605Z","shell.execute_reply.started":"2022-03-08T00:03:16.796244Z","shell.execute_reply":"2022-03-08T00:03:19.448955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Experiement with first top 3 training data\ntr_df = doc_df.iloc[:3]","metadata":{"execution":{"iopub.status.busy":"2022-03-12T09:56:26.197075Z","iopub.execute_input":"2022-03-12T09:56:26.197535Z","iopub.status.idle":"2022-03-12T09:56:26.207794Z","shell.execute_reply.started":"2022-03-12T09:56:26.197477Z","shell.execute_reply":"2022-03-12T09:56:26.206959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_checkpoints,add_prefix_space=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T10:33:47.213909Z","iopub.execute_input":"2022-03-12T10:33:47.214253Z","iopub.status.idle":"2022-03-12T10:34:05.586526Z","shell.execute_reply.started":"2022-03-12T10:33:47.214221Z","shell.execute_reply":"2022-03-12T10:34:05.585333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DataLoader\n### outputs: tokens and attention. \nDuring training it also provides labels.\nDuring inference it also provides word ids to help convert token predictions into word predictions.","metadata":{}},{"cell_type":"code","source":"# IGNORE_INDEX = -100\n# NON_LABEL = -1\n# DO WE LABEL ALL SUBTOKENS???\n\nLABEL_ALL_SUBTOKENS = True\n\nclass dataset(Dataset):\n  def __init__(self, dataframe, tokenizer, max_len, get_wids):\n        self.len = len(dataframe)\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        self.get_wids = get_wids # for validation\n\n  def __getitem__(self, index):\n        # GET TEXT AND WORD LABELS \n        text = self.data.text[index]        \n        word_labels = self.data.elements[index] if not self.get_wids else None\n\n        # TOKENIZE TEXT\n        encoding = self.tokenizer(text.split(),\n                             is_split_into_words=True,\n                             #return_offsets_mapping=True, \n                             padding='max_length', \n                             truncation=True, \n                             max_length=self.max_len)\n        word_ids = encoding.word_ids()  \n        \n        # CREATE TARGETS\n        if not self.get_wids:\n            previous_word_idx = None\n            label_ids = []\n            for word_idx in word_ids:                            \n                if word_idx is None:\n                    label_ids.append(-100)\n                elif word_idx != previous_word_idx:              \n                    label_ids.append( labels_to_ids[word_labels[word_idx]] )\n                else:\n                    if LABEL_ALL_SUBTOKENS:\n                        label_ids.append( labels_to_ids[word_labels[word_idx]] )\n                    else:\n                        label_ids.append(-100)\n                previous_word_idx = word_idx\n            encoding['labels'] = label_ids\n\n        # CONVERT TO TORCH TENSORS\n        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n        if self.get_wids: \n            word_ids2 = [w if w is not None else -1 for w in word_ids]\n            item['wids'] = torch.as_tensor(word_ids2)\n        \n        return item\n\n  def __len__(self):\n        return self.len","metadata":{"execution":{"iopub.status.busy":"2022-03-12T10:50:32.408909Z","iopub.execute_input":"2022-03-12T10:50:32.409199Z","iopub.status.idle":"2022-03-12T10:50:32.4247Z","shell.execute_reply.started":"2022-03-12T10:50:32.409171Z","shell.execute_reply":"2022-03-12T10:50:32.423717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CHOOSE VALIDATION INDEXES (that match my TF notebook)\nIDS = tr_df.id.unique()\nprint('There are',len(IDS),'train texts. We will split 90% 10% for validation.')\n\n# TRAIN VALID SPLIT 90% 10%\nnp.random.seed(42)\ntrain_idx = np.random.choice(np.arange(len(IDS)),int(0.9*len(IDS)),replace=False)\nvalid_idx = np.setdiff1d(np.arange(len(IDS)),train_idx)\nnp.random.seed(None)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T10:51:13.383022Z","iopub.execute_input":"2022-03-12T10:51:13.383383Z","iopub.status.idle":"2022-03-12T10:51:13.397224Z","shell.execute_reply.started":"2022-03-12T10:51:13.383346Z","shell.execute_reply":"2022-03-12T10:51:13.396332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CREATE TRAIN SUBSET AND VALID SUBSET\ndata = tr_df[['id','text', 'elements']]\ntrain_dataset = data.loc[data['id'].isin(IDS[train_idx]),['text', 'elements']].reset_index(drop=True)\ntest_dataset = data.loc[data['id'].isin(IDS[valid_idx])].reset_index(drop=True)\n\nprint(\"FULL Dataset: {}\".format(data.shape))\nprint(\"TRAIN Dataset: {}\".format(train_dataset.shape))\nprint(\"TEST Dataset: {}\".format(test_dataset.shape))\n\ntraining_set = dataset(train_dataset, tokenizer, 1024, False)\ntesting_set = dataset(test_dataset, tokenizer, 1024, True)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T10:54:23.559678Z","iopub.execute_input":"2022-03-12T10:54:23.560129Z","iopub.status.idle":"2022-03-12T10:54:23.578185Z","shell.execute_reply.started":"2022-03-12T10:54:23.560088Z","shell.execute_reply":"2022-03-12T10:54:23.577367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TRAIN DATASET AND VALID DATASET\ntrain_params = {'batch_size': 3,\n                'shuffle': True,\n                'num_workers': 2,\n                'pin_memory':True\n                }\n\ntest_params = {'batch_size': 3,\n                'shuffle': False,\n                'num_workers': 2,\n                'pin_memory':True\n                }\n\ntraining_loader = DataLoader(training_set, **train_params)\ntesting_loader = DataLoader(testing_set, **test_params)\n\n# TEST DATASET\n# test_texts_set = dataset(test_texts, tokenizer, config['max_length'], True)\n# test_texts_loader = DataLoader(test_texts_set, **test_params)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T10:54:26.089514Z","iopub.execute_input":"2022-03-12T10:54:26.090509Z","iopub.status.idle":"2022-03-12T10:54:26.118945Z","shell.execute_reply.started":"2022-03-12T10:54:26.090452Z","shell.execute_reply":"2022-03-12T10:54:26.11775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}